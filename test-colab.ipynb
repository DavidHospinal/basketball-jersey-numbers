{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Basketball Jersey Numbers OCR - Google Colab\n",
    "\n",
    "Sistema de deteccion de numeros en camisetas de baloncesto usando YOLOv8\n",
    "\n",
    "**Modelo**: basketball-jersey-numbers-ocr/7  \n",
    "**GPU**: NVIDIA Tesla T4  \n",
    "**Inferencia**: 100% local (costo cero)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_instructions"
   },
   "source": [
    "## Configuracion del Runtime\n",
    "\n",
    "**IMPORTANTE**: Antes de ejecutar, verifica que el runtime tenga GPU:\n",
    "\n",
    "1. Runtime > Change runtime type\n",
    "2. Hardware accelerator: **GPU (T4)**\n",
    "3. Save"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "install_dependencies",
    "ExecuteTime": {
     "end_time": "2026-02-07T23:16:35.954968300Z",
     "start_time": "2026-02-07T23:14:47.105526600Z"
    }
   },
   "source": "# CELDA 1: Instalacion de dependencias\n# Ejecutar esta celda primero (tarda ~2-3 minutos)\n\nprint(\"Instalando dependencias para Basketball Jersey OCR...\")\nprint(\"Este proceso puede tardar 2-3 minutos\\n\")\n\n# Instalar dependencias principales\n!pip install -q inference supervision gradio roboflow pillow opencv-python\n\nprint(\"\\n[OK] Dependencias instaladas correctamente\")\nprint(\"Nota: Los warnings de compatibilidad de pandas/cryptography son normales y no afectan el funcionamiento\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instalando dependencias para Basketball Jersey OCR...\n",
      "Este proceso puede tardar 2-3 minutos\n",
      "\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m105.7/105.7 kB\u001B[0m \u001B[31m9.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Installing build dependencies ... \u001B[?25l\u001B[?25hdone\n",
      "  Getting requirements to build wheel ... \u001B[?25l\u001B[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m68.6/68.6 kB\u001B[0m \u001B[31m8.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m91.2/91.2 kB\u001B[0m \u001B[31m11.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m99.4/99.4 kB\u001B[0m \u001B[31m13.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m44.0/44.0 kB\u001B[0m \u001B[31m5.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m56.6/56.6 kB\u001B[0m \u001B[31m6.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m46.8/46.8 kB\u001B[0m \u001B[31m5.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m42.2/42.2 kB\u001B[0m \u001B[31m4.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m48.5/48.5 kB\u001B[0m \u001B[31m5.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m981.5/981.5 kB\u001B[0m \u001B[31m38.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.0/3.0 MB\u001B[0m \u001B[31m78.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m40.0/40.0 MB\u001B[0m \u001B[31m24.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m190.1/190.1 kB\u001B[0m \u001B[31m17.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m75.9/75.9 kB\u001B[0m \u001B[31m6.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m217.4/217.4 kB\u001B[0m \u001B[31m15.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m91.8/91.8 kB\u001B[0m \u001B[31m8.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m66.8/66.8 kB\u001B[0m \u001B[31m8.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m49.9/49.9 MB\u001B[0m \u001B[31m19.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m62.5/62.5 MB\u001B[0m \u001B[31m12.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m81.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m93.2/93.2 kB\u001B[0m \u001B[31m11.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m243.4/243.4 kB\u001B[0m \u001B[31m28.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m64.4/64.4 kB\u001B[0m \u001B[31m6.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.1/1.1 MB\u001B[0m \u001B[31m63.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m139.3/139.3 kB\u001B[0m \u001B[31m18.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m14.3/14.3 MB\u001B[0m \u001B[31m117.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m0:01\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m98.2/98.2 kB\u001B[0m \u001B[31m13.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m147.8/147.8 kB\u001B[0m \u001B[31m19.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m95.5/95.5 kB\u001B[0m \u001B[31m11.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m395.0/395.0 kB\u001B[0m \u001B[31m37.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.4/1.4 MB\u001B[0m \u001B[31m61.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m93.2/93.2 kB\u001B[0m \u001B[31m12.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m119.3/119.3 kB\u001B[0m \u001B[31m16.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m47.5/47.5 kB\u001B[0m \u001B[31m5.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m16.0/16.0 MB\u001B[0m \u001B[31m83.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m948.6/948.6 kB\u001B[0m \u001B[31m63.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m68.7/68.7 MB\u001B[0m \u001B[31m10.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m65.5/65.5 kB\u001B[0m \u001B[31m7.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.4/12.4 MB\u001B[0m \u001B[31m114.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m0:01\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.5/1.5 MB\u001B[0m \u001B[31m83.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.5/5.5 MB\u001B[0m \u001B[31m133.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m155.6/155.6 kB\u001B[0m \u001B[31m19.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m444.8/444.8 kB\u001B[0m \u001B[31m45.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m104.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m160.7/160.7 kB\u001B[0m \u001B[31m20.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m45.7/45.7 kB\u001B[0m \u001B[31m5.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m255.6/255.6 kB\u001B[0m \u001B[31m31.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m310.0/310.0 kB\u001B[0m \u001B[31m37.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.5/2.5 MB\u001B[0m \u001B[31m100.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m292.3/292.3 kB\u001B[0m \u001B[31m33.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m72.0/72.0 kB\u001B[0m \u001B[31m9.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m67.2/67.2 kB\u001B[0m \u001B[31m8.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m104.9/104.9 kB\u001B[0m \u001B[31m13.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.8/1.8 MB\u001B[0m \u001B[31m70.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m46.3/46.3 kB\u001B[0m \u001B[31m5.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m72.5/72.5 kB\u001B[0m \u001B[31m9.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m939.7/939.7 kB\u001B[0m \u001B[31m67.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m61.3/61.3 MB\u001B[0m \u001B[31m11.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m:00:01\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.5/4.5 MB\u001B[0m \u001B[31m135.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.9/2.9 MB\u001B[0m \u001B[31m109.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m51.0/51.0 kB\u001B[0m \u001B[31m5.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m163.5/163.5 kB\u001B[0m \u001B[31m21.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m504.9/504.9 kB\u001B[0m \u001B[31m50.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.4/2.4 MB\u001B[0m \u001B[31m114.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m57.3/57.3 kB\u001B[0m \u001B[31m7.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m304.1/304.1 kB\u001B[0m \u001B[31m32.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m566.4/566.4 kB\u001B[0m \u001B[31m51.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m86.0/86.0 kB\u001B[0m \u001B[31m11.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m154.8/154.8 kB\u001B[0m \u001B[31m19.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.0/12.0 MB\u001B[0m \u001B[31m120.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m0:01\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m101.9/101.9 kB\u001B[0m \u001B[31m13.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m46.0/46.0 kB\u001B[0m \u001B[31m5.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m345.1/345.1 kB\u001B[0m \u001B[31m32.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m331.1/331.1 kB\u001B[0m \u001B[31m37.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m86.8/86.8 kB\u001B[0m \u001B[31m11.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m154.5/154.5 kB\u001B[0m \u001B[31m20.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m17.5/17.5 MB\u001B[0m \u001B[31m97.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m978.2/978.2 kB\u001B[0m \u001B[31m71.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.8/2.8 MB\u001B[0m \u001B[31m119.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.2/3.2 MB\u001B[0m \u001B[31m112.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m44.8/44.8 kB\u001B[0m \u001B[31m5.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m180.7/180.7 kB\u001B[0m \u001B[31m19.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m300.6/300.6 kB\u001B[0m \u001B[31m37.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m256.2/256.2 kB\u001B[0m \u001B[31m32.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Building wheel for paho-mqtt (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Building wheel for pybase64 (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "  Building wheel for pyvips (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Building wheel for docopt (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Building wheel for iopath (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Building wheel for langdetect (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.4 which is incompatible.\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\n",
      "spopt 0.7.0 requires shapely>=2.1.0, but you have shapely 2.0.7 which is incompatible.\n",
      "bigframes 2.33.0 requires rich<14,>=12.4.4, but you have rich 14.3.2 which is incompatible.\n",
      "typeguard 4.4.4 requires typing_extensions>=4.14.0, but you have typing-extensions 4.12.2 which is incompatible.\n",
      "esda 2.8.1 requires shapely>=2.1, but you have shapely 2.0.7 which is incompatible.\n",
      "sse-starlette 3.2.0 requires starlette>=0.49.1, but you have starlette 0.46.2 which is incompatible.\n",
      "google-adk 1.23.0 requires starlette<1.0.0,>=0.49.1, but you have starlette 0.46.2 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0m\n",
      "[OK] Dependencias instaladas correctamente\n",
      "Nota: Los warnings de compatibilidad de pandas/cryptography son normales y no afectan el funcionamiento\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "verify_gpu",
    "ExecuteTime": {
     "end_time": "2026-02-07T23:17:35.031047200Z",
     "start_time": "2026-02-07T23:17:30.996289Z"
    }
   },
   "source": [
    "# CELDA 2: Verificacion de GPU\n",
    "# Confirma que estas usando GPU Tesla T4\n",
    "\n",
    "import torch\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"VERIFICACION DE GPU\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU disponible: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Memoria total: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"Memoria asignada: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
    "    print(f\"Memoria en cache: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n",
    "    print(\"\\n[OK] GPU detectada correctamente\")\n",
    "else:\n",
    "    print(\"[ERROR] GPU no detectada\")\n",
    "    print(\"Verifica: Runtime > Change runtime type > GPU\")\n",
    "\n",
    "print(\"=\" * 70)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VERIFICACION DE GPU\n",
      "======================================================================\n",
      "GPU disponible: Tesla T4\n",
      "CUDA version: 12.6\n",
      "Memoria total: 15.83 GB\n",
      "Memoria asignada: 0.00 GB\n",
      "Memoria en cache: 0.00 GB\n",
      "\n",
      "[OK] GPU detectada correctamente\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "imports",
    "ExecuteTime": {
     "end_time": "2026-02-07T23:17:52.671199500Z",
     "start_time": "2026-02-07T23:17:44.078704400Z"
    }
   },
   "source": "# CELDA 3: Importaciones\n\nimport os\nimport csv\nimport re\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import List, Dict, Tuple\n\nimport cv2\nimport numpy as np\nimport gradio as gr\nfrom PIL import Image\n\nprint(\"[OK] Modulos importados correctamente\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Modulos importados correctamente\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jersey_analyzer_class",
    "ExecuteTime": {
     "end_time": "2026-02-07T23:17:59.026129700Z",
     "start_time": "2026-02-07T23:17:58.684784Z"
    }
   },
   "source": "# CELDA 4: Clase JerseyAnalyzer (VERSION CORREGIDA con soporte VLM)\n# Analizador de dorsales con soporte para respuestas VLM y YOLO\n\nclass JerseyAnalyzer:\n    \"\"\"Analizador de numeros de camisetas con soporte VLM y YOLO\"\"\"\n\n    def __init__(self, api_key: str, model_id: str = \"basketball-jersey-numbers-ocr/7\"):\n        \"\"\"\n        Inicializa el analizador con inferencia local en GPU\n\n        Args:\n            api_key: Roboflow API key (solo para descargar modelo)\n            model_id: ID del modelo en formato workspace/project/version\n        \"\"\"\n        self.api_key = api_key\n        self.model_id = model_id\n        self.model = None\n\n        # Usar rutas de Colab (/content/)\n        self.output_dir = Path(\"/content/outputs/detections\")\n        self.output_dir.mkdir(parents=True, exist_ok=True)\n        self.csv_log = Path(\"/content/jersey_log.csv\")\n\n        # Inicializar CSV si no existe\n        if not self.csv_log.exists():\n            with open(self.csv_log, 'w', newline='', encoding='utf-8') as f:\n                writer = csv.writer(f)\n                writer.writerow(['Timestamp', 'Numero Detectado', 'Confianza', 'Archivo'])\n\n        self._cargar_modelo()\n\n    def _cargar_modelo(self):\n        \"\"\"Carga el modelo para inferencia local en GPU\"\"\"\n        try:\n            print(f\"\\nCargando modelo {self.model_id} para inferencia local...\")\n            from inference import get_model\n\n            # Inicializar modelo con API key (solo descarga, no consume creditos)\n            self.model = get_model(\n                model_id=self.model_id,\n                api_key=self.api_key\n            )\n            print(f\"[OK] Modelo cargado en GPU local\")\n\n        except Exception as e:\n            print(f\"[ERROR] Error al cargar modelo: {e}\")\n            raise\n\n    def detectar_numeros(\n        self,\n        imagen: np.ndarray,\n        confianza_min: float = 0.4\n    ) -> Tuple[np.ndarray, List[Dict]]:\n        \"\"\"\n        Detecta numeros en camiseta con inferencia local\n        CORREGIDO: Maneja respuestas VLM y YOLO\n\n        Args:\n            imagen: Imagen en formato numpy array (RGB)\n            confianza_min: Umbral minimo de confianza (0.0-1.0)\n\n        Returns:\n            Tupla de (imagen_anotada, lista_detecciones)\n        \"\"\"\n        if self.model is None:\n            raise RuntimeError(\"Modelo no inicializado\")\n\n        # Inferencia local (NO consume creditos de API)\n        resultado = self.model.infer(imagen, confidence=confianza_min)\n\n        # Manejar si resultado es lista\n        if isinstance(resultado, list):\n            resultado = resultado[0]\n\n        # Detectar tipo de respuesta\n        tipo_respuesta = type(resultado).__name__\n        print(f\"[DEBUG] Tipo de respuesta: {tipo_respuesta}\")\n\n        detecciones = []\n\n        # CASO 1: Respuesta VLM (LMMInferenceResponse)\n        if hasattr(resultado, 'response'):\n            print(\"[INFO] Detectado modelo VLM\")\n            texto_respuesta = str(getattr(resultado, 'response', ''))\n            print(f\"[INFO] Respuesta del modelo: {texto_respuesta}\")\n\n            # Extraer numero del texto usando regex\n            numeros = re.findall(r'\\b\\d+\\b', texto_respuesta)\n\n            if numeros:\n                numero_detectado = numeros[0]\n                print(f\"[OK] Numero extraido: {numero_detectado}\")\n\n                # Crear deteccion con bbox centrado\n                h, w = imagen.shape[:2]\n                detecciones.append({\n                    'numero': numero_detectado,\n                    'confianza': 0.95,  # VLM tiene alta confianza\n                    'bbox': {\n                        'x': w // 2,\n                        'y': h // 2,\n                        'width': int(w * 0.6),\n                        'height': int(h * 0.6)\n                    }\n                })\n            else:\n                print(\"[ADVERTENCIA] No se pudo extraer numero del texto\")\n\n        # CASO 2: Respuesta YOLO estandar\n        elif hasattr(resultado, 'predictions'):\n            print(\"[INFO] Detectado modelo YOLO\")\n            for pred in resultado.predictions:\n                detecciones.append({\n                    'numero': pred.class_name,\n                    'confianza': round(pred.confidence, 3),\n                    'bbox': {\n                        'x': int(pred.x),\n                        'y': int(pred.y),\n                        'width': int(pred.width),\n                        'height': int(pred.height)\n                    }\n                })\n\n        # CASO 3: Tipo desconocido - debug\n        else:\n            print(f\"[ERROR] Tipo de respuesta desconocido: {tipo_respuesta}\")\n            print(f\"[DEBUG] Atributos: {dir(resultado)}\")\n\n        # Visualizar detecciones\n        if detecciones:\n            imagen_anotada = self._visualizar_detecciones_opencv(imagen, detecciones)\n        else:\n            imagen_anotada = imagen.copy()\n\n        # Guardar en log CSV\n        self._guardar_en_log(detecciones)\n\n        return imagen_anotada, detecciones\n\n    def _visualizar_detecciones_opencv(self, imagen: np.ndarray, detecciones: List[Dict]) -> np.ndarray:\n        \"\"\"\n        Dibuja bounding boxes con OpenCV (compatible con VLM y YOLO)\n        \"\"\"\n        img = imagen.copy()\n\n        for det in detecciones:\n            bbox = det['bbox']\n            numero = det['numero']\n            conf = det['confianza']\n\n            # Calcular coordenadas del rectangulo\n            x1 = int(bbox['x'] - bbox['width'] / 2)\n            y1 = int(bbox['y'] - bbox['height'] / 2)\n            x2 = int(bbox['x'] + bbox['width'] / 2)\n            y2 = int(bbox['y'] + bbox['height'] / 2)\n\n            # Asegurar que coordenadas esten dentro de la imagen\n            h, w = img.shape[:2]\n            x1, x2 = max(0, x1), min(w, x2)\n            y1, y2 = max(0, y1), min(h, y2)\n\n            # Dibujar bounding box verde\n            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 3)\n\n            # Preparar etiqueta\n            label = f\"{numero} ({conf:.2f})\"\n\n            # Calcular tamaño del texto\n            font = cv2.FONT_HERSHEY_SIMPLEX\n            font_scale = 1.2\n            thickness = 2\n            (text_w, text_h), _ = cv2.getTextSize(label, font, font_scale, thickness)\n\n            # Dibujar fondo para el texto\n            cv2.rectangle(img, (x1, y1 - text_h - 10), (x1 + text_w, y1), (0, 255, 0), -1)\n\n            # Dibujar texto\n            cv2.putText(img, label, (x1, y1 - 5),\n                       font, font_scale, (0, 0, 0), thickness)\n\n        return img\n\n    def _guardar_en_log(self, detecciones: List[Dict]):\n        \"\"\"Añade detecciones al archivo CSV de log\"\"\"\n        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n\n        with open(self.csv_log, 'a', newline='', encoding='utf-8') as f:\n            writer = csv.writer(f)\n            for det in detecciones:\n                writer.writerow([\n                    timestamp,\n                    det['numero'],\n                    det['confianza'],\n                    'gradio_upload'\n                ])\n\n    def calcular_estadisticas(self, detecciones: List[Dict]) -> Dict:\n        \"\"\"Calcula estadisticas de las detecciones\"\"\"\n        if not detecciones:\n            return {\n                'total': 0,\n                'confianza_promedio': 0.0,\n                'confianza_max': 0.0,\n                'confianza_min': 0.0\n            }\n\n        confianzas = [d['confianza'] for d in detecciones]\n\n        return {\n            'total': len(detecciones),\n            'confianza_promedio': round(np.mean(confianzas), 3),\n            'confianza_max': round(max(confianzas), 3),\n            'confianza_min': round(min(confianzas), 3)\n        }\n\n    def exportar_csv(self, detecciones: List[Dict], filename: str = None) -> str:\n        \"\"\"Exporta detecciones actuales a CSV\"\"\"\n        if filename is None:\n            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n            filename = f\"detecciones_{timestamp}.csv\"\n\n        filepath = self.output_dir / filename\n\n        with open(filepath, 'w', newline='', encoding='utf-8') as f:\n            writer = csv.DictWriter(f, fieldnames=['numero', 'confianza', 'bbox'])\n            writer.writeheader()\n            writer.writerows(detecciones)\n\n        return str(filepath)\n\n\nprint(\"[OK] Clase JerseyAnalyzer definida (VERSION CORREGIDA con soporte VLM)\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Clase JerseyAnalyzer definida (VERSION CORREGIDA con soporte VLM)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gradio_interface",
    "ExecuteTime": {
     "end_time": "2026-02-07T23:20:09.461099300Z",
     "start_time": "2026-02-07T23:20:09.198100100Z"
    }
   },
   "source": [
    "# CELDA 5: Interfaz Gradio\n",
    "# Define la interfaz web para deteccion de dorsales\n",
    "\n",
    "def crear_interfaz_gradio(analyzer: JerseyAnalyzer):\n",
    "    \"\"\"Crea interfaz Gradio profesional con todas las funcionalidades\"\"\"\n",
    "\n",
    "    def analizar_imagen(imagen, confianza_min):\n",
    "        \"\"\"Procesa imagen y retorna resultados\"\"\"\n",
    "        if imagen is None:\n",
    "            return None, \"No se cargo ninguna imagen\", None\n",
    "\n",
    "        # Convertir a numpy array RGB\n",
    "        if isinstance(imagen, Image.Image):\n",
    "            imagen = np.array(imagen)\n",
    "\n",
    "        # Detectar numeros\n",
    "        imagen_anotada, detecciones = analyzer.detectar_numeros(\n",
    "            imagen,\n",
    "            confianza_min=confianza_min\n",
    "        )\n",
    "\n",
    "        # Calcular estadisticas\n",
    "        stats = analyzer.calcular_estadisticas(detecciones)\n",
    "\n",
    "        # Formatear resultados\n",
    "        texto_stats = f\"\"\"\n",
    "ESTADISTICAS DE DETECCION:\n",
    "- Total de numeros detectados: {stats['total']}\n",
    "- Confianza promedio: {stats['confianza_promedio']:.3f}\n",
    "- Confianza maxima: {stats['confianza_max']:.3f}\n",
    "- Confianza minima: {stats['confianza_min']:.3f}\n",
    "        \"\"\"\n",
    "\n",
    "        # Formatear tabla de detecciones\n",
    "        tabla_detecciones = [\n",
    "            [d['numero'], f\"{d['confianza']:.3f}\"]\n",
    "            for d in detecciones\n",
    "        ]\n",
    "\n",
    "        return imagen_anotada, texto_stats, tabla_detecciones\n",
    "\n",
    "    def limpiar_todo():\n",
    "        \"\"\"Limpia todos los campos\"\"\"\n",
    "        return None, \"\", None\n",
    "\n",
    "    def exportar_resultados_csv(detecciones_tabla):\n",
    "        \"\"\"Exporta tabla actual a CSV\"\"\"\n",
    "        if not detecciones_tabla:\n",
    "            return \"No hay detecciones para exportar\"\n",
    "\n",
    "        detecciones = [\n",
    "            {\n",
    "                'numero': row[0],\n",
    "                'confianza': float(row[1]),\n",
    "                'bbox': {}\n",
    "            }\n",
    "            for row in detecciones_tabla\n",
    "        ]\n",
    "\n",
    "        filepath = analyzer.exportar_csv(detecciones)\n",
    "        return f\"Exportado a: {filepath}\"\n",
    "\n",
    "    # Crear interfaz con Blocks\n",
    "    with gr.Blocks(\n",
    "        title=\"Basketball Jersey Numbers OCR\",\n",
    "        theme=gr.themes.Soft()\n",
    "    ) as demo:\n",
    "\n",
    "        gr.Markdown(\"# Basketball Jersey Numbers OCR\")\n",
    "        gr.Markdown(\"Deteccion de numeros en camisetas de baloncesto - Inferencia Local GPU\")\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1):\n",
    "                imagen_entrada = gr.Image(\n",
    "                    label=\"Imagen de entrada\",\n",
    "                    type=\"numpy\",\n",
    "                    sources=[\"upload\", \"webcam\"]\n",
    "                )\n",
    "\n",
    "                confianza_slider = gr.Slider(\n",
    "                    minimum=0.1,\n",
    "                    maximum=0.9,\n",
    "                    value=0.4,\n",
    "                    step=0.05,\n",
    "                    label=\"Confianza minima\"\n",
    "                )\n",
    "\n",
    "                with gr.Row():\n",
    "                    btn_analizar = gr.Button(\"Analizar\", variant=\"primary\")\n",
    "                    btn_limpiar = gr.Button(\"Limpiar\")\n",
    "\n",
    "            with gr.Column(scale=1):\n",
    "                imagen_salida = gr.Image(\n",
    "                    label=\"Detecciones\",\n",
    "                    type=\"numpy\"\n",
    "                )\n",
    "\n",
    "                texto_stats = gr.Textbox(\n",
    "                    label=\"Estadisticas\",\n",
    "                    lines=6,\n",
    "                    interactive=False\n",
    "                )\n",
    "\n",
    "        gr.Markdown(\"### Historial de Detecciones\")\n",
    "\n",
    "        tabla_detecciones = gr.Dataframe(\n",
    "            headers=[\"Numero\", \"Confianza\"],\n",
    "            label=\"Resultados\",\n",
    "            interactive=False\n",
    "        )\n",
    "\n",
    "        with gr.Row():\n",
    "            btn_exportar = gr.Button(\"Exportar a CSV\")\n",
    "            texto_exportar = gr.Textbox(\n",
    "                label=\"Estado de exportacion\",\n",
    "                interactive=False\n",
    "            )\n",
    "\n",
    "        # Conectar eventos\n",
    "        btn_analizar.click(\n",
    "            fn=analizar_imagen,\n",
    "            inputs=[imagen_entrada, confianza_slider],\n",
    "            outputs=[imagen_salida, texto_stats, tabla_detecciones]\n",
    "        )\n",
    "\n",
    "        btn_limpiar.click(\n",
    "            fn=limpiar_todo,\n",
    "            outputs=[imagen_entrada, texto_stats, tabla_detecciones]\n",
    "        )\n",
    "\n",
    "        btn_exportar.click(\n",
    "            fn=exportar_resultados_csv,\n",
    "            inputs=[tabla_detecciones],\n",
    "            outputs=[texto_exportar]\n",
    "        )\n",
    "\n",
    "    return demo\n",
    "\n",
    "\n",
    "print(\"[OK] Funcion de interfaz Gradio definida\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Funcion de interfaz Gradio definida\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "main_execution",
    "ExecuteTime": {
     "end_time": "2026-02-07T23:49:21.236685200Z",
     "start_time": "2026-02-07T23:22:13.071039700Z"
    }
   },
   "source": [
    "# CELDA 6: Ejecucion Principal\n",
    "# IMPORTANTE: Ingresa tu API key de Roboflow antes de ejecutar\n",
    "\n",
    "# Configuracion\n",
    "ROBOFLOW_API_KEY = \"\"  # INGRESA TU API KEY AQUI\n",
    "\n",
    "if not ROBOFLOW_API_KEY:\n",
    "    print(\"[ERROR] Debes ingresar tu Roboflow API key en la variable ROBOFLOW_API_KEY\")\n",
    "    print(\"\\nInstrucciones:\")\n",
    "    print(\"1. Ve a https://app.roboflow.com\")\n",
    "    print(\"2. Settings > API Keys\")\n",
    "    print(\"3. Copia tu Private API Key\")\n",
    "    print(\"4. Pegala en la variable ROBOFLOW_API_KEY arriba\")\n",
    "else:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"BASKETBALL JERSEY NUMBERS OCR - INFERENCIA LOCAL\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Cerrar cualquier demo de Gradio anterior\n",
    "    try:\n",
    "        import gradio as gr\n",
    "        gr.close_all()\n",
    "        print(\"\\n[INFO] Cerrando sesiones anteriores de Gradio...\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # LIMPIAR MEMORIA GPU antes de cargar el modelo\n",
    "    print(\"[INFO] Liberando memoria GPU...\")\n",
    "    import torch\n",
    "    import gc\n",
    "    \n",
    "    # Limpiar cache de CUDA\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Forzar recoleccion de basura\n",
    "    gc.collect()\n",
    "    \n",
    "    # Mostrar memoria disponible\n",
    "    if torch.cuda.is_available():\n",
    "        memoria_libre = torch.cuda.mem_get_info()[0] / 1e9\n",
    "        memoria_total = torch.cuda.mem_get_info()[1] / 1e9\n",
    "        print(f\"[INFO] Memoria GPU libre: {memoria_libre:.2f} GB / {memoria_total:.2f} GB\")\n",
    "\n",
    "    # Inicializar analizador\n",
    "    print(\"\\nInicializando analizador...\")\n",
    "    print(\"[ADVERTENCIA] El modelo VLM es pesado (~2.4GB). Cargando...\")\n",
    "    \n",
    "    analyzer = JerseyAnalyzer(api_key=ROBOFLOW_API_KEY)\n",
    "\n",
    "    # Crear y lanzar interfaz Gradio\n",
    "    print(\"\\nLanzando interfaz Gradio...\")\n",
    "    print(\"Se generara una URL publica que puedes abrir en cualquier navegador\")\n",
    "    \n",
    "    demo = crear_interfaz_gradio(analyzer)\n",
    "    \n",
    "    # Lanzar sin especificar puerto fijo (Gradio encuentra uno libre automaticamente)\n",
    "    demo.launch(\n",
    "        share=True,  # Genera URL publica\n",
    "        show_error=True,\n",
    "        debug=True\n",
    "    )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BASKETBALL JERSEY NUMBERS OCR - INFERENCIA LOCAL\n",
      "======================================================================\n",
      "\n",
      "[INFO] Cerrando sesiones anteriores de Gradio...\n",
      "[INFO] Liberando memoria GPU...\n",
      "[INFO] Memoria GPU libre: 15.72 GB / 15.83 GB\n",
      "\n",
      "Inicializando analizador...\n",
      "[ADVERTENCIA] El modelo VLM es pesado (~2.4GB). Cargando...\n",
      "\n",
      "Cargando modelo basketball-jersey-numbers-ocr/7 para inferencia local...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2;36m[02/07/26 23:22:13]\u001B[0m\u001B[2;36m \u001B[0m\u001B[33mWARNING \u001B[0m Your inference package version \u001B[1;36m0.64\u001B[0m.\u001B[1;36m7\u001B[0m is out of date! Please upgrade to \u001B]8;id=915531;file:///usr/local/lib/python3.12/dist-packages/inference/core/__init__.py\u001B\\\u001B[2m__init__.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=153484;file:///usr/local/lib/python3.12/dist-packages/inference/core/__init__.py#41\u001B\\\u001B[2m41\u001B[0m\u001B]8;;\u001B\\\n",
       "\u001B[2;36m                    \u001B[0m         version \u001B[1;36m1.0\u001B[0m.0rc1 of inference for the latest features and bug fixes by  \u001B[2m              \u001B[0m\n",
       "\u001B[2;36m                    \u001B[0m         running `pip install --upgrade inference`.                              \u001B[2m              \u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/07/26 23:22:13] </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> Your inference package version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.64</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> is out of date! Please upgrade to <a href=\"file:///usr/local/lib/python3.12/dist-packages/inference/core/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///usr/local/lib/python3.12/dist-packages/inference/core/__init__.py#41\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">41</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>.0rc1 of inference for the latest features and bug fixes by  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         running `pip install --upgrade inference`.                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelDependencyMissing: Your `inference` configuration does not support SAM3 model. Install SAM3 dependencies and set CORE_MODEL_SAM3_ENABLED to True.\n",
      "ModelDependencyMissing: Your `inference` configuration does not support Gaze Detection model. Use pip install 'inference[gaze]' to install missing requirements.To suppress this warning, set CORE_MODEL_GAZE_ENABLED to False.\n",
      "FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "ModelDependencyMissing: Your `inference` configuration does not support YoloWorld model. Use pip install 'inference[yolo-world]' to install missing requirements.To suppress this warning, set CORE_MODEL_YOLO_WORLD_ENABLED to False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolved model_id: basketball-jersey-numbers-ocr/7, dataset_id: basketball-jersey-numbers-ocr, version_id: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47f5c7f97e7647769a68888dd6bbe5eb"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a5b6cc62b6b4782932dbc2e7b0e5ecb"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e306652560a48dc82bb068a4f8f1f40"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9d0d8899d746431fa939827635c46df1"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d6ef9543d61a43adabe2a0ac7d9e10ed"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "557d7b8ae7c942039ebc884fee9457e2"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Modelo cargado en GPU local\n",
      "\n",
      "Lanzando interfaz Gradio...\n",
      "Se generara una URL publica que puedes abrir en cualquier navegador\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
      "* Running on public URL: https://95bda1c86d60cd004a.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"https://95bda1c86d60cd004a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Tipo de respuesta: LMMInferenceResponse\n",
      "[INFO] Detectado modelo VLM\n",
      "[INFO] Respuesta del modelo:  28\n",
      "[OK] Numero extraido: 28\n",
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7860 <> https://95bda1c86d60cd004a.gradio.live\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usage_instructions"
   },
   "source": [
    "## Instrucciones de Uso\n",
    "\n",
    "### 1. Ejecutar Celdas en Orden\n",
    "1. Celda 1: Instalacion de dependencias (2-3 minutos)\n",
    "2. Celda 2: Verificacion de GPU\n",
    "3. Celda 3: Importaciones\n",
    "4. Celda 4: Clase JerseyAnalyzer\n",
    "5. Celda 5: Interfaz Gradio\n",
    "6. Celda 6: Ejecucion (ingresa tu API key primero)\n",
    "\n",
    "### 2. Obtener API Key de Roboflow\n",
    "1. Ir a https://app.roboflow.com\n",
    "2. Settings > API Keys\n",
    "3. Copiar Private API Key\n",
    "4. Pegar en variable `ROBOFLOW_API_KEY` de la Celda 6\n",
    "\n",
    "### 3. Usar la Interfaz\n",
    "- Subir imagen de camiseta de baloncesto\n",
    "- Ajustar slider de confianza minima (0.1 - 0.9)\n",
    "- Hacer clic en \"Analizar\"\n",
    "- Ver resultados con bounding boxes\n",
    "- Exportar a CSV si es necesario\n",
    "\n",
    "### 4. Archivos Generados\n",
    "- `/content/jersey_log.csv` - Historial completo de detecciones\n",
    "- `/content/outputs/detections/` - Exportaciones CSV individuales\n",
    "\n",
    "### 5. Notas Importantes\n",
    "- La API key solo se usa para descargar el modelo (primera vez)\n",
    "- Todas las inferencias son locales en GPU T4 (costo cero)\n",
    "- El modelo se cachea, la segunda ejecucion es instantanea\n",
    "- La sesion de Colab expira tras 12 horas de inactividad"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
