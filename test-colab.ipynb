{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Basketball Jersey Numbers OCR - Google Colab\n",
    "\n",
    "Sistema de deteccion de numeros en camisetas de baloncesto usando YOLOv8\n",
    "\n",
    "**Modelo**: basketball-jersey-numbers-ocr/7  \n",
    "**GPU**: NVIDIA Tesla T4  \n",
    "**Inferencia**: 100% local (costo cero)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_instructions"
   },
   "source": [
    "## Configuracion del Runtime\n",
    "\n",
    "**IMPORTANTE**: Antes de ejecutar, verifica que el runtime tenga GPU:\n",
    "\n",
    "1. Runtime > Change runtime type\n",
    "2. Hardware accelerator: **GPU (T4)**\n",
    "3. Save"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "install_dependencies",
    "ExecuteTime": {
     "end_time": "2026-02-02T23:41:32.059600400Z",
     "start_time": "2026-02-02T23:39:38.480798100Z"
    }
   },
   "source": [
    "# CELDA 1: Instalacion de dependencias\n",
    "# Ejecutar esta celda primero (tarda ~2-3 minutos)\n",
    "\n",
    "print(\"Instalando dependencias para Basketball Jersey OCR...\")\n",
    "print(\"Este proceso puede tardar 2-3 minutos\\n\")\n",
    "\n",
    "# Instalar dependencias principales\n",
    "!pip install -q inference supervision gradio roboflow pillow\n",
    "\n",
    "print(\"\\n[OK] Dependencias instaladas correctamente\")\n",
    "print(\"Nota: Los warnings de compatibilidad de pandas/cryptography son normales y no afectan el funcionamiento\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instalando dependencias para Basketball Jersey OCR...\n",
      "Este proceso puede tardar 2-3 minutos\n",
      "\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m105.7/105.7 kB\u001B[0m \u001B[31m4.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Installing build dependencies ... \u001B[?25l\u001B[?25hdone\n",
      "  Getting requirements to build wheel ... \u001B[?25l\u001B[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m68.6/68.6 kB\u001B[0m \u001B[31m9.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m91.2/91.2 kB\u001B[0m \u001B[31m11.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m99.4/99.4 kB\u001B[0m \u001B[31m13.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m44.0/44.0 kB\u001B[0m \u001B[31m4.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m56.6/56.6 kB\u001B[0m \u001B[31m7.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m46.8/46.8 kB\u001B[0m \u001B[31m5.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m42.2/42.2 kB\u001B[0m \u001B[31m5.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m48.5/48.5 kB\u001B[0m \u001B[31m5.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m981.5/981.5 kB\u001B[0m \u001B[31m41.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.0/3.0 MB\u001B[0m \u001B[31m75.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m40.0/40.0 MB\u001B[0m \u001B[31m29.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m190.1/190.1 kB\u001B[0m \u001B[31m22.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m75.9/75.9 kB\u001B[0m \u001B[31m9.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m212.4/212.4 kB\u001B[0m \u001B[31m26.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m91.8/91.8 kB\u001B[0m \u001B[31m11.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m66.8/66.8 kB\u001B[0m \u001B[31m8.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m49.9/49.9 MB\u001B[0m \u001B[31m12.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0mm\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m48.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m93.2/93.2 kB\u001B[0m \u001B[31m12.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m243.4/243.4 kB\u001B[0m \u001B[31m29.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m64.4/64.4 kB\u001B[0m \u001B[31m7.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.1/1.1 MB\u001B[0m \u001B[31m47.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m139.3/139.3 kB\u001B[0m \u001B[31m19.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m14.3/14.3 MB\u001B[0m \u001B[31m56.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m98.2/98.2 kB\u001B[0m \u001B[31m13.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m147.8/147.8 kB\u001B[0m \u001B[31m19.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m95.5/95.5 kB\u001B[0m \u001B[31m12.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m395.0/395.0 kB\u001B[0m \u001B[31m38.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.4/1.4 MB\u001B[0m \u001B[31m52.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m93.2/93.2 kB\u001B[0m \u001B[31m12.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m119.3/119.3 kB\u001B[0m \u001B[31m16.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m47.5/47.5 kB\u001B[0m \u001B[31m5.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m16.0/16.0 MB\u001B[0m \u001B[31m55.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m948.6/948.6 kB\u001B[0m \u001B[31m45.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m68.7/68.7 MB\u001B[0m \u001B[31m10.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m62.5/62.5 MB\u001B[0m \u001B[31m16.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m65.5/65.5 kB\u001B[0m \u001B[31m8.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.4/12.4 MB\u001B[0m \u001B[31m75.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.5/1.5 MB\u001B[0m \u001B[31m59.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.5/5.5 MB\u001B[0m \u001B[31m79.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m155.6/155.6 kB\u001B[0m \u001B[31m18.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m444.8/444.8 kB\u001B[0m \u001B[31m44.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m70.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m160.7/160.7 kB\u001B[0m \u001B[31m20.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m45.7/45.7 kB\u001B[0m \u001B[31m5.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m255.6/255.6 kB\u001B[0m \u001B[31m29.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m310.0/310.0 kB\u001B[0m \u001B[31m35.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.5/2.5 MB\u001B[0m \u001B[31m76.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m292.3/292.3 kB\u001B[0m \u001B[31m34.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m72.0/72.0 kB\u001B[0m \u001B[31m9.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m67.2/67.2 kB\u001B[0m \u001B[31m8.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m104.9/104.9 kB\u001B[0m \u001B[31m13.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.8/1.8 MB\u001B[0m \u001B[31m66.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m46.3/46.3 kB\u001B[0m \u001B[31m5.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m72.5/72.5 kB\u001B[0m \u001B[31m9.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m939.7/939.7 kB\u001B[0m \u001B[31m51.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m61.3/61.3 MB\u001B[0m \u001B[31m12.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0mm\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.5/4.5 MB\u001B[0m \u001B[31m68.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.9/2.9 MB\u001B[0m \u001B[31m61.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m51.0/51.0 kB\u001B[0m \u001B[31m6.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m163.5/163.5 kB\u001B[0m \u001B[31m19.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m504.9/504.9 kB\u001B[0m \u001B[31m42.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.4/2.4 MB\u001B[0m \u001B[31m62.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m57.3/57.3 kB\u001B[0m \u001B[31m7.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m304.1/304.1 kB\u001B[0m \u001B[31m35.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m566.3/566.3 kB\u001B[0m \u001B[31m38.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m86.0/86.0 kB\u001B[0m \u001B[31m11.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m154.8/154.8 kB\u001B[0m \u001B[31m19.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.0/12.0 MB\u001B[0m \u001B[31m44.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m101.9/101.9 kB\u001B[0m \u001B[31m13.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m46.0/46.0 kB\u001B[0m \u001B[31m5.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m345.1/345.1 kB\u001B[0m \u001B[31m22.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m331.1/331.1 kB\u001B[0m \u001B[31m20.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m86.8/86.8 kB\u001B[0m \u001B[31m11.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m154.5/154.5 kB\u001B[0m \u001B[31m15.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m17.5/17.5 MB\u001B[0m \u001B[31m29.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m978.2/978.2 kB\u001B[0m \u001B[31m30.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.8/2.8 MB\u001B[0m \u001B[31m34.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.2/3.2 MB\u001B[0m \u001B[31m36.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m44.8/44.8 kB\u001B[0m \u001B[31m5.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m180.7/180.7 kB\u001B[0m \u001B[31m22.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m300.6/300.6 kB\u001B[0m \u001B[31m21.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m256.2/256.2 kB\u001B[0m \u001B[31m28.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Building wheel for paho-mqtt (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Building wheel for pybase64 (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "  Building wheel for pyvips (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Building wheel for docopt (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Building wheel for iopath (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Building wheel for langdetect (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.4 which is incompatible.\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\n",
      "bigframes 2.33.0 requires rich<14,>=12.4.4, but you have rich 14.3.2 which is incompatible.\n",
      "sse-starlette 3.2.0 requires starlette>=0.49.1, but you have starlette 0.46.2 which is incompatible.\n",
      "spopt 0.7.0 requires shapely>=2.1.0, but you have shapely 2.0.7 which is incompatible.\n",
      "google-adk 1.23.0 requires starlette<1.0.0,>=0.49.1, but you have starlette 0.46.2 which is incompatible.\n",
      "typeguard 4.4.4 requires typing_extensions>=4.14.0, but you have typing-extensions 4.12.2 which is incompatible.\n",
      "esda 2.8.1 requires shapely>=2.1, but you have shapely 2.0.7 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0m\n",
      "[OK] Dependencias instaladas correctamente\n",
      "Nota: Los warnings de compatibilidad de pandas/cryptography son normales y no afectan el funcionamiento\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "verify_gpu",
    "ExecuteTime": {
     "end_time": "2026-02-02T23:43:04.429375400Z",
     "start_time": "2026-02-02T23:43:00.267981600Z"
    }
   },
   "source": [
    "# CELDA 2: Verificacion de GPU\n",
    "# Confirma que estas usando GPU Tesla T4\n",
    "\n",
    "import torch\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"VERIFICACION DE GPU\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU disponible: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Memoria total: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"Memoria asignada: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
    "    print(f\"Memoria en cache: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n",
    "    print(\"\\n[OK] GPU detectada correctamente\")\n",
    "else:\n",
    "    print(\"[ERROR] GPU no detectada\")\n",
    "    print(\"Verifica: Runtime > Change runtime type > GPU\")\n",
    "\n",
    "print(\"=\" * 70)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VERIFICACION DE GPU\n",
      "======================================================================\n",
      "GPU disponible: Tesla T4\n",
      "CUDA version: 12.6\n",
      "Memoria total: 15.83 GB\n",
      "Memoria asignada: 0.00 GB\n",
      "Memoria en cache: 0.00 GB\n",
      "\n",
      "[OK] GPU detectada correctamente\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "imports",
    "ExecuteTime": {
     "end_time": "2026-02-02T23:43:26.036669600Z",
     "start_time": "2026-02-02T23:43:17.266580900Z"
    }
   },
   "source": [
    "# CELDA 3: Importaciones\n",
    "\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "\n",
    "print(\"[OK] Modulos importados correctamente\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Modulos importados correctamente\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jersey_analyzer_class",
    "ExecuteTime": {
     "end_time": "2026-02-02T23:43:38.399830900Z",
     "start_time": "2026-02-02T23:43:38.050852300Z"
    }
   },
   "source": [
    "# CELDA 4: Clase JerseyAnalyzer\n",
    "# Analizador de dorsales con inferencia local en GPU\n",
    "\n",
    "class JerseyAnalyzer:\n",
    "    \"\"\"Analizador de numeros de camisetas de baloncesto con inferencia local\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str, model_id: str = \"basketball-jersey-numbers-ocr/7\"):\n",
    "        \"\"\"\n",
    "        Inicializa el analizador con inferencia local en GPU\n",
    "\n",
    "        Args:\n",
    "            api_key: Roboflow API key (solo para descargar modelo)\n",
    "            model_id: ID del modelo en formato workspace/project/version\n",
    "        \"\"\"\n",
    "        self.api_key = api_key\n",
    "        self.model_id = model_id\n",
    "        self.model = None\n",
    "        \n",
    "        # Usar rutas de Colab (/content/)\n",
    "        self.output_dir = Path(\"/content/outputs/detections\")\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.csv_log = Path(\"/content/jersey_log.csv\")\n",
    "\n",
    "        # Inicializar CSV si no existe\n",
    "        if not self.csv_log.exists():\n",
    "            with open(self.csv_log, 'w', newline='', encoding='utf-8') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(['Timestamp', 'Numero Detectado', 'Confianza', 'Archivo'])\n",
    "\n",
    "        self._cargar_modelo()\n",
    "\n",
    "    def _cargar_modelo(self):\n",
    "        \"\"\"Carga el modelo para inferencia local en GPU\"\"\"\n",
    "        try:\n",
    "            print(f\"\\nCargando modelo {self.model_id} para inferencia local...\")\n",
    "            from inference import get_model\n",
    "\n",
    "            # Inicializar modelo con API key (solo descarga, no consume creditos)\n",
    "            self.model = get_model(\n",
    "                model_id=self.model_id,\n",
    "                api_key=self.api_key\n",
    "            )\n",
    "            print(f\"[OK] Modelo cargado en GPU local\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Error al cargar modelo: {e}\")\n",
    "            raise\n",
    "\n",
    "    def detectar_numeros(\n",
    "        self,\n",
    "        imagen: np.ndarray,\n",
    "        confianza_min: float = 0.4\n",
    "    ) -> Tuple[np.ndarray, List[Dict]]:\n",
    "        \"\"\"\n",
    "        Detecta numeros en camiseta con inferencia local\n",
    "\n",
    "        Args:\n",
    "            imagen: Imagen en formato numpy array (RGB)\n",
    "            confianza_min: Umbral minimo de confianza (0.0-1.0)\n",
    "\n",
    "        Returns:\n",
    "            Tupla de (imagen_anotada, lista_detecciones)\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Modelo no inicializado\")\n",
    "\n",
    "        # Inferencia local (NO consume creditos de API)\n",
    "        resultados = self.model.infer(imagen, confidence=confianza_min)[0]\n",
    "\n",
    "        # Procesar detecciones\n",
    "        detecciones = []\n",
    "        for pred in resultados.predictions:\n",
    "            detecciones.append({\n",
    "                'numero': pred.class_name,\n",
    "                'confianza': round(pred.confidence, 3),\n",
    "                'bbox': {\n",
    "                    'x': int(pred.x),\n",
    "                    'y': int(pred.y),\n",
    "                    'width': int(pred.width),\n",
    "                    'height': int(pred.height)\n",
    "                }\n",
    "            })\n",
    "\n",
    "        # Visualizar con supervision\n",
    "        imagen_anotada = self._visualizar_detecciones(imagen, resultados)\n",
    "\n",
    "        # Guardar en log CSV\n",
    "        self._guardar_en_log(detecciones)\n",
    "\n",
    "        return imagen_anotada, detecciones\n",
    "\n",
    "    def _visualizar_detecciones(self, imagen: np.ndarray, resultados) -> np.ndarray:\n",
    "        \"\"\"Dibuja bounding boxes y etiquetas con supervision\"\"\"\n",
    "        try:\n",
    "            import supervision as sv\n",
    "\n",
    "            # Convertir resultados a formato supervision\n",
    "            detections = sv.Detections.from_inference(resultados)\n",
    "\n",
    "            # Configurar anotadores\n",
    "            box_annotator = sv.BoxAnnotator(\n",
    "                thickness=3,\n",
    "                color=sv.Color.from_hex(\"#00FF00\")\n",
    "            )\n",
    "\n",
    "            label_annotator = sv.LabelAnnotator(\n",
    "                text_scale=1.2,\n",
    "                text_thickness=2,\n",
    "                text_color=sv.Color.WHITE,\n",
    "                color=sv.Color.from_hex(\"#00FF00\")\n",
    "            )\n",
    "\n",
    "            # Generar etiquetas con clase y confianza\n",
    "            labels = [\n",
    "                f\"{pred.class_name} ({pred.confidence:.2f})\"\n",
    "                for pred in resultados.predictions\n",
    "            ]\n",
    "\n",
    "            # Anotar imagen\n",
    "            imagen_anotada = box_annotator.annotate(\n",
    "                scene=imagen.copy(),\n",
    "                detections=detections\n",
    "            )\n",
    "            imagen_anotada = label_annotator.annotate(\n",
    "                scene=imagen_anotada,\n",
    "                detections=detections,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            return imagen_anotada\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ADVERTENCIA] Error en visualizacion: {e}\")\n",
    "            return imagen\n",
    "\n",
    "    def _guardar_en_log(self, detecciones: List[Dict]):\n",
    "        \"\"\"Añade detecciones al archivo CSV de log\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        with open(self.csv_log, 'a', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for det in detecciones:\n",
    "                writer.writerow([\n",
    "                    timestamp,\n",
    "                    det['numero'],\n",
    "                    det['confianza'],\n",
    "                    'gradio_upload'\n",
    "                ])\n",
    "\n",
    "    def calcular_estadisticas(self, detecciones: List[Dict]) -> Dict:\n",
    "        \"\"\"Calcula estadisticas de las detecciones\"\"\"\n",
    "        if not detecciones:\n",
    "            return {\n",
    "                'total': 0,\n",
    "                'confianza_promedio': 0.0,\n",
    "                'confianza_max': 0.0,\n",
    "                'confianza_min': 0.0\n",
    "            }\n",
    "\n",
    "        confianzas = [d['confianza'] for d in detecciones]\n",
    "\n",
    "        return {\n",
    "            'total': len(detecciones),\n",
    "            'confianza_promedio': round(np.mean(confianzas), 3),\n",
    "            'confianza_max': round(max(confianzas), 3),\n",
    "            'confianza_min': round(min(confianzas), 3)\n",
    "        }\n",
    "\n",
    "    def exportar_csv(self, detecciones: List[Dict], filename: str = None) -> str:\n",
    "        \"\"\"Exporta detecciones actuales a CSV\"\"\"\n",
    "        if filename is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"detecciones_{timestamp}.csv\"\n",
    "\n",
    "        filepath = self.output_dir / filename\n",
    "\n",
    "        with open(filepath, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=['numero', 'confianza', 'bbox'])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(detecciones)\n",
    "\n",
    "        return str(filepath)\n",
    "\n",
    "\n",
    "print(\"[OK] Clase JerseyAnalyzer definida\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Clase JerseyAnalyzer definida\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gradio_interface",
    "ExecuteTime": {
     "end_time": "2026-02-02T23:43:52.763925100Z",
     "start_time": "2026-02-02T23:43:52.495254800Z"
    }
   },
   "source": [
    "# CELDA 5: Interfaz Gradio\n",
    "# Define la interfaz web para deteccion de dorsales\n",
    "\n",
    "def crear_interfaz_gradio(analyzer: JerseyAnalyzer):\n",
    "    \"\"\"Crea interfaz Gradio profesional con todas las funcionalidades\"\"\"\n",
    "\n",
    "    def analizar_imagen(imagen, confianza_min):\n",
    "        \"\"\"Procesa imagen y retorna resultados\"\"\"\n",
    "        if imagen is None:\n",
    "            return None, \"No se cargo ninguna imagen\", None\n",
    "\n",
    "        # Convertir a numpy array RGB\n",
    "        if isinstance(imagen, Image.Image):\n",
    "            imagen = np.array(imagen)\n",
    "\n",
    "        # Detectar numeros\n",
    "        imagen_anotada, detecciones = analyzer.detectar_numeros(\n",
    "            imagen,\n",
    "            confianza_min=confianza_min\n",
    "        )\n",
    "\n",
    "        # Calcular estadisticas\n",
    "        stats = analyzer.calcular_estadisticas(detecciones)\n",
    "\n",
    "        # Formatear resultados\n",
    "        texto_stats = f\"\"\"\n",
    "ESTADISTICAS DE DETECCION:\n",
    "- Total de numeros detectados: {stats['total']}\n",
    "- Confianza promedio: {stats['confianza_promedio']:.3f}\n",
    "- Confianza maxima: {stats['confianza_max']:.3f}\n",
    "- Confianza minima: {stats['confianza_min']:.3f}\n",
    "        \"\"\"\n",
    "\n",
    "        # Formatear tabla de detecciones\n",
    "        tabla_detecciones = [\n",
    "            [d['numero'], f\"{d['confianza']:.3f}\"]\n",
    "            for d in detecciones\n",
    "        ]\n",
    "\n",
    "        return imagen_anotada, texto_stats, tabla_detecciones\n",
    "\n",
    "    def limpiar_todo():\n",
    "        \"\"\"Limpia todos los campos\"\"\"\n",
    "        return None, \"\", None\n",
    "\n",
    "    def exportar_resultados_csv(detecciones_tabla):\n",
    "        \"\"\"Exporta tabla actual a CSV\"\"\"\n",
    "        if not detecciones_tabla:\n",
    "            return \"No hay detecciones para exportar\"\n",
    "\n",
    "        detecciones = [\n",
    "            {\n",
    "                'numero': row[0],\n",
    "                'confianza': float(row[1]),\n",
    "                'bbox': {}\n",
    "            }\n",
    "            for row in detecciones_tabla\n",
    "        ]\n",
    "\n",
    "        filepath = analyzer.exportar_csv(detecciones)\n",
    "        return f\"Exportado a: {filepath}\"\n",
    "\n",
    "    # Crear interfaz con Blocks\n",
    "    with gr.Blocks(\n",
    "        title=\"Basketball Jersey Numbers OCR\",\n",
    "        theme=gr.themes.Soft()\n",
    "    ) as demo:\n",
    "\n",
    "        gr.Markdown(\"# Basketball Jersey Numbers OCR\")\n",
    "        gr.Markdown(\"Deteccion de numeros en camisetas de baloncesto - Inferencia Local GPU\")\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1):\n",
    "                imagen_entrada = gr.Image(\n",
    "                    label=\"Imagen de entrada\",\n",
    "                    type=\"numpy\",\n",
    "                    sources=[\"upload\", \"webcam\"]\n",
    "                )\n",
    "\n",
    "                confianza_slider = gr.Slider(\n",
    "                    minimum=0.1,\n",
    "                    maximum=0.9,\n",
    "                    value=0.4,\n",
    "                    step=0.05,\n",
    "                    label=\"Confianza minima\"\n",
    "                )\n",
    "\n",
    "                with gr.Row():\n",
    "                    btn_analizar = gr.Button(\"Analizar\", variant=\"primary\")\n",
    "                    btn_limpiar = gr.Button(\"Limpiar\")\n",
    "\n",
    "            with gr.Column(scale=1):\n",
    "                imagen_salida = gr.Image(\n",
    "                    label=\"Detecciones\",\n",
    "                    type=\"numpy\"\n",
    "                )\n",
    "\n",
    "                texto_stats = gr.Textbox(\n",
    "                    label=\"Estadisticas\",\n",
    "                    lines=6,\n",
    "                    interactive=False\n",
    "                )\n",
    "\n",
    "        gr.Markdown(\"### Historial de Detecciones\")\n",
    "\n",
    "        tabla_detecciones = gr.Dataframe(\n",
    "            headers=[\"Numero\", \"Confianza\"],\n",
    "            label=\"Resultados\",\n",
    "            interactive=False\n",
    "        )\n",
    "\n",
    "        with gr.Row():\n",
    "            btn_exportar = gr.Button(\"Exportar a CSV\")\n",
    "            texto_exportar = gr.Textbox(\n",
    "                label=\"Estado de exportacion\",\n",
    "                interactive=False\n",
    "            )\n",
    "\n",
    "        # Conectar eventos\n",
    "        btn_analizar.click(\n",
    "            fn=analizar_imagen,\n",
    "            inputs=[imagen_entrada, confianza_slider],\n",
    "            outputs=[imagen_salida, texto_stats, tabla_detecciones]\n",
    "        )\n",
    "\n",
    "        btn_limpiar.click(\n",
    "            fn=limpiar_todo,\n",
    "            outputs=[imagen_entrada, texto_stats, tabla_detecciones]\n",
    "        )\n",
    "\n",
    "        btn_exportar.click(\n",
    "            fn=exportar_resultados_csv,\n",
    "            inputs=[tabla_detecciones],\n",
    "            outputs=[texto_exportar]\n",
    "        )\n",
    "\n",
    "    return demo\n",
    "\n",
    "\n",
    "print(\"[OK] Funcion de interfaz Gradio definida\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Funcion de interfaz Gradio definida\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "main_execution",
    "ExecuteTime": {
     "end_time": "2026-02-02T23:49:29.559169900Z",
     "start_time": "2026-02-02T23:44:55.822535800Z"
    }
   },
   "source": [
    "# CELDA 6: Ejecucion Principal\n",
    "# IMPORTANTE: Ingresa tu API key de Roboflow antes de ejecutar\n",
    "\n",
    "# Configuracion\n",
    "ROBOFLOW_API_KEY = \"00BKbj1JjjJshZXYvnKY\"  # INGRESA TU API KEY AQUI\n",
    "\n",
    "if not ROBOFLOW_API_KEY:\n",
    "    print(\"[ERROR] Debes ingresar tu Roboflow API key en la variable ROBOFLOW_API_KEY\")\n",
    "    print(\"\\nInstrucciones:\")\n",
    "    print(\"1. Ve a https://app.roboflow.com\")\n",
    "    print(\"2. Settings > API Keys\")\n",
    "    print(\"3. Copia tu Private API Key\")\n",
    "    print(\"4. Pegala en la variable ROBOFLOW_API_KEY arriba\")\n",
    "else:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"BASKETBALL JERSEY NUMBERS OCR - INFERENCIA LOCAL\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Inicializar analizador\n",
    "    print(\"\\nInicializando analizador...\")\n",
    "    analyzer = JerseyAnalyzer(api_key=ROBOFLOW_API_KEY)\n",
    "\n",
    "    # Crear y lanzar interfaz Gradio\n",
    "    print(\"\\nLanzando interfaz Gradio...\")\n",
    "    print(\"Se generara una URL publica que puedes abrir en cualquier navegador\")\n",
    "    \n",
    "    demo = crear_interfaz_gradio(analyzer)\n",
    "    \n",
    "    demo.launch(\n",
    "        share=True,  # Genera URL publica\n",
    "        server_name=\"0.0.0.0\",\n",
    "        server_port=7860,\n",
    "        show_error=True\n",
    "    )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BASKETBALL JERSEY NUMBERS OCR - INFERENCIA LOCAL\n",
      "======================================================================\n",
      "\n",
      "Inicializando analizador...\n",
      "\n",
      "Cargando modelo basketball-jersey-numbers-ocr/7 para inferencia local...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelDependencyMissing: Your `inference` configuration does not support SAM3 model. Install SAM3 dependencies and set CORE_MODEL_SAM3_ENABLED to True.\n",
      "ModelDependencyMissing: Your `inference` configuration does not support Gaze Detection model. Use pip install 'inference[gaze]' to install missing requirements.To suppress this warning, set CORE_MODEL_GAZE_ENABLED to False.\n",
      "FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "ModelDependencyMissing: Your `inference` configuration does not support YoloWorld model. Use pip install 'inference[yolo-world]' to install missing requirements.To suppress this warning, set CORE_MODEL_YOLO_WORLD_ENABLED to False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolved model_id: basketball-jersey-numbers-ocr/7, dataset_id: basketball-jersey-numbers-ocr, version_id: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a3adc03a84041368fb059fa0a4cb276"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "095ba20d93d04cdf8e1f4612edb58646"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be818b64ccd74750862a82d457cb2e09"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "82fefb72563847679bbf660729d59e46"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7894847abb4d47d89d706a625a9a9cfc"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f545ce1653514d48b6b7aa25b438700f"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Modelo cargado en GPU local\n",
      "\n",
      "Lanzando interfaz Gradio...\n",
      "Se generara una URL publica que puedes abrir en cualquier navegador\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://c56481a511cbde635c.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"https://c56481a511cbde635c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usage_instructions"
   },
   "source": [
    "## Instrucciones de Uso\n",
    "\n",
    "### 1. Ejecutar Celdas en Orden\n",
    "1. Celda 1: Instalacion de dependencias (2-3 minutos)\n",
    "2. Celda 2: Verificacion de GPU\n",
    "3. Celda 3: Importaciones\n",
    "4. Celda 4: Clase JerseyAnalyzer\n",
    "5. Celda 5: Interfaz Gradio\n",
    "6. Celda 6: Ejecucion (ingresa tu API key primero)\n",
    "\n",
    "### 2. Obtener API Key de Roboflow\n",
    "1. Ir a https://app.roboflow.com\n",
    "2. Settings > API Keys\n",
    "3. Copiar Private API Key\n",
    "4. Pegar en variable `ROBOFLOW_API_KEY` de la Celda 6\n",
    "\n",
    "### 3. Usar la Interfaz\n",
    "- Subir imagen de camiseta de baloncesto\n",
    "- Ajustar slider de confianza minima (0.1 - 0.9)\n",
    "- Hacer clic en \"Analizar\"\n",
    "- Ver resultados con bounding boxes\n",
    "- Exportar a CSV si es necesario\n",
    "\n",
    "### 4. Archivos Generados\n",
    "- `/content/jersey_log.csv` - Historial completo de detecciones\n",
    "- `/content/outputs/detections/` - Exportaciones CSV individuales\n",
    "\n",
    "### 5. Notas Importantes\n",
    "- La API key solo se usa para descargar el modelo (primera vez)\n",
    "- Todas las inferencias son locales en GPU T4 (costo cero)\n",
    "- El modelo se cachea, la segunda ejecucion es instantanea\n",
    "- La sesion de Colab expira tras 12 horas de inactividad"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
