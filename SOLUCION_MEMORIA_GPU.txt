================================================================================
SOLUCION: CUDA out of memory - GPU llena
================================================================================

ERROR:
CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity
of 14.74 GiB of which 52.12 MiB is free. Process 24546 has 14.69 GiB memory
in use.

CAUSA:
El modelo VLM (SmolVLM) que usa basketball-jersey-numbers-ocr/7 es muy pesado
(~2.4 GB) y hay un proceso anterior usando casi toda la GPU (14.69 GB de 14.74 GB).

================================================================================
SOLUCION INMEDIATA: Reiniciar Runtime de Colab
================================================================================

PASO 1: Reiniciar Runtime

En Colab (navegador):
1. Ir a https://colab.research.google.com
2. Abrir el notebook test-colab.ipynb
3. Runtime > Restart runtime
4. Confirmar "Yes"

O desde PyCharm:
1. Kernel > Restart Kernel
2. Confirmar

PASO 2: Volver a ejecutar celdas

Ejecutar en orden:
1. Celda 1: Instalacion (2-3 min)
2. Celda 2: Verificar GPU
3. Celda 3: Importaciones
4. Celda 4: Clase JerseyAnalyzer
5. Celda 5: Interfaz Gradio
6. Celda 6: Ejecucion (AHORA con limpieza de memoria automatica)

PASO 3: Verificar memoria disponible

Al ejecutar Celda 6, deberia mostrar:
[INFO] Memoria GPU libre: ~14.XX GB / 14.74 GB

Si muestra menos de 10 GB libres, algo mas esta usando la GPU.

================================================================================
SOLUCION ALTERNATIVA: Usar Modelo YOLO Mas Ligero
================================================================================

El modelo actual (basketball-jersey-numbers-ocr/7) es un VLM pesado.

OPCION 1: Cambiar a un modelo YOLO estandar mas ligero

En Celda 6, cambiar:

ANTES:
analyzer = JerseyAnalyzer(api_key=ROBOFLOW_API_KEY)

DESPUES:
analyzer = JerseyAnalyzer(
    api_key=ROBOFLOW_API_KEY,
    model_id="yolov8n-640"  # Modelo generico ligero
)

OPCION 2: Buscar otro modelo de jerseys en Roboflow

1. Ir a: https://universe.roboflow.com
2. Buscar: "basketball jersey number"
3. Filtrar por:
   - Model Type: Object Detection (no VLM)
   - Framework: YOLOv8
4. Seleccionar un modelo mas ligero
5. Copiar el model_id (ej: "usuario/proyecto/version")
6. Usar ese model_id en JerseyAnalyzer

================================================================================
SOLUCION AVANZADA: Liberar Memoria Manualmente
================================================================================

CELDA NUEVA - Agregar ANTES de Celda 6:

# CELDA: Limpiar Memoria GPU
import torch
import gc

print("Liberando memoria GPU...")

# Limpiar cache de CUDA
torch.cuda.empty_cache()

# Forzar recoleccion de basura
gc.collect()

# Mostrar estado de memoria
if torch.cuda.is_available():
    memoria_libre = torch.cuda.mem_get_info()[0] / 1e9
    memoria_total = torch.cuda.mem_get_info()[1] / 1e9
    print(f"Memoria GPU libre: {memoria_libre:.2f} GB / {memoria_total:.2f} GB")
    print(f"Memoria GPU usada: {memoria_total - memoria_libre:.2f} GB")

print("\n[OK] Memoria liberada. Lista para cargar modelo.")

================================================================================
DIAGNOSTICO: Ver que esta usando la GPU
================================================================================

CELDA NUEVA - Diagnostico:

import torch

if torch.cuda.is_available():
    print("Estado de memoria GPU:")
    print(f"Total: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
    print(f"Asignada: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB")
    print(f"Reservada: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB")

    # Ver memoria disponible
    memoria_info = torch.cuda.mem_get_info()
    print(f"\nMemoria libre: {memoria_info[0] / 1e9:.2f} GB")
    print(f"Memoria total: {memoria_info[1] / 1e9:.2f} GB")
    print(f"Memoria en uso: {(memoria_info[1] - memoria_info[0]) / 1e9:.2f} GB")

    # Porcentaje de uso
    porcentaje_uso = ((memoria_info[1] - memoria_info[0]) / memoria_info[1]) * 100
    print(f"\nUso de GPU: {porcentaje_uso:.1f}%")

    if porcentaje_uso > 80:
        print("\n[ADVERTENCIA] GPU casi llena. Considera reiniciar runtime.")

================================================================================
POR QUE EL MODELO VLM ES TAN PESADO
================================================================================

El modelo basketball-jersey-numbers-ocr/7 usa SmolVLM, que es un:
- Vision Language Model (VLM)
- Modelo multimodal que procesa texto + imagenes
- Basado en transformers (HuggingFace)
- Tamaño del modelo: ~2.4 GB
- Memoria en ejecucion: ~3-4 GB

Un modelo YOLO estandar solo necesita:
- Tamaño del modelo: ~6-50 MB
- Memoria en ejecucion: ~500 MB - 1 GB

Por eso es mejor usar YOLO si la memoria es limitada.

================================================================================
RECOMENDACION FINAL
================================================================================

Para este proyecto, MEJOR OPCION:

1. Reiniciar runtime de Colab (limpia TODA la memoria)
2. Ejecutar celdas 1-6 en orden
3. Si falla por memoria, cambiar a modelo YOLO ligero

Ventajas de YOLO sobre VLM:
- Mas rapido
- Menos memoria
- Resultados similares o mejores para deteccion de numeros
- Bounding boxes precisos (no aproximados)

Desventaja:
- VLM puede leer texto mas complejo
- YOLO solo detecta objetos pre-entrenados

Para numeros de jerseys, YOLO es suficiente y mas eficiente.

================================================================================
SI PERSISTE EL ERROR
================================================================================

1. Verificar que no haya otras notebooks/procesos usando la GPU:
   - En Colab: Runtime > Manage sessions
   - Terminar sesiones antiguas

2. Usar un runtime nuevo:
   - Runtime > Disconnect and delete runtime
   - Runtime > Connect to new runtime

3. Reducir el tamaño de imagen de entrada:
   - Modificar en crear_interfaz_gradio()
   - Resize imagenes a 640x640 antes de inferencia

4. Contactar soporte de Colab si el problema persiste:
   - Puede ser un problema temporal del servidor
   - O limite de recursos del plan gratuito

================================================================================
