{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Basketball Jersey Numbers OCR - Google Colab\n",
    "\n",
    "Sistema de deteccion de numeros en camisetas de baloncesto usando YOLOv8\n",
    "\n",
    "**Modelo**: basketball-jersey-numbers-ocr/7  \n",
    "**GPU**: NVIDIA Tesla T4  \n",
    "**Inferencia**: 100% local (costo cero)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_instructions"
   },
   "source": [
    "## Configuracion del Runtime\n",
    "\n",
    "**IMPORTANTE**: Antes de ejecutar, verifica que el runtime tenga GPU:\n",
    "\n",
    "1. Runtime > Change runtime type\n",
    "2. Hardware accelerator: **GPU (T4)**\n",
    "3. Save"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "install_dependencies",
    "ExecuteTime": {
     "end_time": "2026-02-03T22:32:35.201981Z",
     "start_time": "2026-02-03T22:32:27.739999900Z"
    }
   },
   "source": "# CELDA 1: Instalacion de dependencias\n# Ejecutar esta celda primero (tarda ~2-3 minutos)\n\nprint(\"Instalando dependencias para Basketball Jersey OCR...\")\nprint(\"Este proceso puede tardar 2-3 minutos\\n\")\n\n# Instalar dependencias principales\n!pip install -q inference supervision gradio roboflow pillow opencv-python\n\nprint(\"\\n[OK] Dependencias instaladas correctamente\")\nprint(\"Nota: Los warnings de compatibilidad de pandas/cryptography son normales y no afectan el funcionamiento\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instalando dependencias para Basketball Jersey OCR...\n",
      "Este proceso puede tardar 2-3 minutos\n",
      "\n",
      "\n",
      "[OK] Dependencias instaladas correctamente\n",
      "Nota: Los warnings de compatibilidad de pandas/cryptography son normales y no afectan el funcionamiento\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "verify_gpu",
    "ExecuteTime": {
     "end_time": "2026-02-03T22:32:40.959950800Z",
     "start_time": "2026-02-03T22:32:40.770232800Z"
    }
   },
   "source": [
    "# CELDA 2: Verificacion de GPU\n",
    "# Confirma que estas usando GPU Tesla T4\n",
    "\n",
    "import torch\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"VERIFICACION DE GPU\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU disponible: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Memoria total: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"Memoria asignada: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
    "    print(f\"Memoria en cache: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n",
    "    print(\"\\n[OK] GPU detectada correctamente\")\n",
    "else:\n",
    "    print(\"[ERROR] GPU no detectada\")\n",
    "    print(\"Verifica: Runtime > Change runtime type > GPU\")\n",
    "\n",
    "print(\"=\" * 70)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VERIFICACION DE GPU\n",
      "======================================================================\n",
      "GPU disponible: Tesla T4\n",
      "CUDA version: 12.6\n",
      "Memoria total: 15.83 GB\n",
      "Memoria asignada: 4.53 GB\n",
      "Memoria en cache: 9.54 GB\n",
      "\n",
      "[OK] GPU detectada correctamente\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "imports",
    "ExecuteTime": {
     "end_time": "2026-02-03T22:32:50.106753200Z",
     "start_time": "2026-02-03T22:32:49.899374300Z"
    }
   },
   "source": "# CELDA 3: Importaciones\n\nimport os\nimport csv\nimport re\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import List, Dict, Tuple\n\nimport cv2\nimport numpy as np\nimport gradio as gr\nfrom PIL import Image\n\nprint(\"[OK] Modulos importados correctamente\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Modulos importados correctamente\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jersey_analyzer_class",
    "ExecuteTime": {
     "end_time": "2026-02-03T22:32:55.859212700Z",
     "start_time": "2026-02-03T22:32:55.626075400Z"
    }
   },
   "source": "# CELDA 4: Clase JerseyAnalyzer (VERSION CORREGIDA con soporte VLM)\n# Analizador de dorsales con soporte para respuestas VLM y YOLO\n\nclass JerseyAnalyzer:\n    \"\"\"Analizador de numeros de camisetas con soporte VLM y YOLO\"\"\"\n\n    def __init__(self, api_key: str, model_id: str = \"basketball-jersey-numbers-ocr/7\"):\n        \"\"\"\n        Inicializa el analizador con inferencia local en GPU\n\n        Args:\n            api_key: Roboflow API key (solo para descargar modelo)\n            model_id: ID del modelo en formato workspace/project/version\n        \"\"\"\n        self.api_key = api_key\n        self.model_id = model_id\n        self.model = None\n\n        # Usar rutas de Colab (/content/)\n        self.output_dir = Path(\"/content/outputs/detections\")\n        self.output_dir.mkdir(parents=True, exist_ok=True)\n        self.csv_log = Path(\"/content/jersey_log.csv\")\n\n        # Inicializar CSV si no existe\n        if not self.csv_log.exists():\n            with open(self.csv_log, 'w', newline='', encoding='utf-8') as f:\n                writer = csv.writer(f)\n                writer.writerow(['Timestamp', 'Numero Detectado', 'Confianza', 'Archivo'])\n\n        self._cargar_modelo()\n\n    def _cargar_modelo(self):\n        \"\"\"Carga el modelo para inferencia local en GPU\"\"\"\n        try:\n            print(f\"\\nCargando modelo {self.model_id} para inferencia local...\")\n            from inference import get_model\n\n            # Inicializar modelo con API key (solo descarga, no consume creditos)\n            self.model = get_model(\n                model_id=self.model_id,\n                api_key=self.api_key\n            )\n            print(f\"[OK] Modelo cargado en GPU local\")\n\n        except Exception as e:\n            print(f\"[ERROR] Error al cargar modelo: {e}\")\n            raise\n\n    def detectar_numeros(\n        self,\n        imagen: np.ndarray,\n        confianza_min: float = 0.4\n    ) -> Tuple[np.ndarray, List[Dict]]:\n        \"\"\"\n        Detecta numeros en camiseta con inferencia local\n        CORREGIDO: Maneja respuestas VLM y YOLO\n\n        Args:\n            imagen: Imagen en formato numpy array (RGB)\n            confianza_min: Umbral minimo de confianza (0.0-1.0)\n\n        Returns:\n            Tupla de (imagen_anotada, lista_detecciones)\n        \"\"\"\n        if self.model is None:\n            raise RuntimeError(\"Modelo no inicializado\")\n\n        # Inferencia local (NO consume creditos de API)\n        resultado = self.model.infer(imagen, confidence=confianza_min)\n\n        # Manejar si resultado es lista\n        if isinstance(resultado, list):\n            resultado = resultado[0]\n\n        # Detectar tipo de respuesta\n        tipo_respuesta = type(resultado).__name__\n        print(f\"[DEBUG] Tipo de respuesta: {tipo_respuesta}\")\n\n        detecciones = []\n\n        # CASO 1: Respuesta VLM (LMMInferenceResponse)\n        if hasattr(resultado, 'response'):\n            print(\"[INFO] Detectado modelo VLM\")\n            texto_respuesta = str(getattr(resultado, 'response', ''))\n            print(f\"[INFO] Respuesta del modelo: {texto_respuesta}\")\n\n            # Extraer numero del texto usando regex\n            numeros = re.findall(r'\\b\\d+\\b', texto_respuesta)\n\n            if numeros:\n                numero_detectado = numeros[0]\n                print(f\"[OK] Numero extraido: {numero_detectado}\")\n\n                # Crear deteccion con bbox centrado\n                h, w = imagen.shape[:2]\n                detecciones.append({\n                    'numero': numero_detectado,\n                    'confianza': 0.95,  # VLM tiene alta confianza\n                    'bbox': {\n                        'x': w // 2,\n                        'y': h // 2,\n                        'width': int(w * 0.6),\n                        'height': int(h * 0.6)\n                    }\n                })\n            else:\n                print(\"[ADVERTENCIA] No se pudo extraer numero del texto\")\n\n        # CASO 2: Respuesta YOLO estandar\n        elif hasattr(resultado, 'predictions'):\n            print(\"[INFO] Detectado modelo YOLO\")\n            for pred in resultado.predictions:\n                detecciones.append({\n                    'numero': pred.class_name,\n                    'confianza': round(pred.confidence, 3),\n                    'bbox': {\n                        'x': int(pred.x),\n                        'y': int(pred.y),\n                        'width': int(pred.width),\n                        'height': int(pred.height)\n                    }\n                })\n\n        # CASO 3: Tipo desconocido - debug\n        else:\n            print(f\"[ERROR] Tipo de respuesta desconocido: {tipo_respuesta}\")\n            print(f\"[DEBUG] Atributos: {dir(resultado)}\")\n\n        # Visualizar detecciones\n        if detecciones:\n            imagen_anotada = self._visualizar_detecciones_opencv(imagen, detecciones)\n        else:\n            imagen_anotada = imagen.copy()\n\n        # Guardar en log CSV\n        self._guardar_en_log(detecciones)\n\n        return imagen_anotada, detecciones\n\n    def _visualizar_detecciones_opencv(self, imagen: np.ndarray, detecciones: List[Dict]) -> np.ndarray:\n        \"\"\"\n        Dibuja bounding boxes con OpenCV (compatible con VLM y YOLO)\n        \"\"\"\n        img = imagen.copy()\n\n        for det in detecciones:\n            bbox = det['bbox']\n            numero = det['numero']\n            conf = det['confianza']\n\n            # Calcular coordenadas del rectangulo\n            x1 = int(bbox['x'] - bbox['width'] / 2)\n            y1 = int(bbox['y'] - bbox['height'] / 2)\n            x2 = int(bbox['x'] + bbox['width'] / 2)\n            y2 = int(bbox['y'] + bbox['height'] / 2)\n\n            # Asegurar que coordenadas esten dentro de la imagen\n            h, w = img.shape[:2]\n            x1, x2 = max(0, x1), min(w, x2)\n            y1, y2 = max(0, y1), min(h, y2)\n\n            # Dibujar bounding box verde\n            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 3)\n\n            # Preparar etiqueta\n            label = f\"{numero} ({conf:.2f})\"\n\n            # Calcular tamaño del texto\n            font = cv2.FONT_HERSHEY_SIMPLEX\n            font_scale = 1.2\n            thickness = 2\n            (text_w, text_h), _ = cv2.getTextSize(label, font, font_scale, thickness)\n\n            # Dibujar fondo para el texto\n            cv2.rectangle(img, (x1, y1 - text_h - 10), (x1 + text_w, y1), (0, 255, 0), -1)\n\n            # Dibujar texto\n            cv2.putText(img, label, (x1, y1 - 5),\n                       font, font_scale, (0, 0, 0), thickness)\n\n        return img\n\n    def _guardar_en_log(self, detecciones: List[Dict]):\n        \"\"\"Añade detecciones al archivo CSV de log\"\"\"\n        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n\n        with open(self.csv_log, 'a', newline='', encoding='utf-8') as f:\n            writer = csv.writer(f)\n            for det in detecciones:\n                writer.writerow([\n                    timestamp,\n                    det['numero'],\n                    det['confianza'],\n                    'gradio_upload'\n                ])\n\n    def calcular_estadisticas(self, detecciones: List[Dict]) -> Dict:\n        \"\"\"Calcula estadisticas de las detecciones\"\"\"\n        if not detecciones:\n            return {\n                'total': 0,\n                'confianza_promedio': 0.0,\n                'confianza_max': 0.0,\n                'confianza_min': 0.0\n            }\n\n        confianzas = [d['confianza'] for d in detecciones]\n\n        return {\n            'total': len(detecciones),\n            'confianza_promedio': round(np.mean(confianzas), 3),\n            'confianza_max': round(max(confianzas), 3),\n            'confianza_min': round(min(confianzas), 3)\n        }\n\n    def exportar_csv(self, detecciones: List[Dict], filename: str = None) -> str:\n        \"\"\"Exporta detecciones actuales a CSV\"\"\"\n        if filename is None:\n            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n            filename = f\"detecciones_{timestamp}.csv\"\n\n        filepath = self.output_dir / filename\n\n        with open(filepath, 'w', newline='', encoding='utf-8') as f:\n            writer = csv.DictWriter(f, fieldnames=['numero', 'confianza', 'bbox'])\n            writer.writeheader()\n            writer.writerows(detecciones)\n\n        return str(filepath)\n\n\nprint(\"[OK] Clase JerseyAnalyzer definida (VERSION CORREGIDA con soporte VLM)\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Clase JerseyAnalyzer definida (VERSION CORREGIDA con soporte VLM)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gradio_interface",
    "ExecuteTime": {
     "end_time": "2026-02-03T22:33:12.771970300Z",
     "start_time": "2026-02-03T22:33:12.536683100Z"
    }
   },
   "source": [
    "# CELDA 5: Interfaz Gradio\n",
    "# Define la interfaz web para deteccion de dorsales\n",
    "\n",
    "def crear_interfaz_gradio(analyzer: JerseyAnalyzer):\n",
    "    \"\"\"Crea interfaz Gradio profesional con todas las funcionalidades\"\"\"\n",
    "\n",
    "    def analizar_imagen(imagen, confianza_min):\n",
    "        \"\"\"Procesa imagen y retorna resultados\"\"\"\n",
    "        if imagen is None:\n",
    "            return None, \"No se cargo ninguna imagen\", None\n",
    "\n",
    "        # Convertir a numpy array RGB\n",
    "        if isinstance(imagen, Image.Image):\n",
    "            imagen = np.array(imagen)\n",
    "\n",
    "        # Detectar numeros\n",
    "        imagen_anotada, detecciones = analyzer.detectar_numeros(\n",
    "            imagen,\n",
    "            confianza_min=confianza_min\n",
    "        )\n",
    "\n",
    "        # Calcular estadisticas\n",
    "        stats = analyzer.calcular_estadisticas(detecciones)\n",
    "\n",
    "        # Formatear resultados\n",
    "        texto_stats = f\"\"\"\n",
    "ESTADISTICAS DE DETECCION:\n",
    "- Total de numeros detectados: {stats['total']}\n",
    "- Confianza promedio: {stats['confianza_promedio']:.3f}\n",
    "- Confianza maxima: {stats['confianza_max']:.3f}\n",
    "- Confianza minima: {stats['confianza_min']:.3f}\n",
    "        \"\"\"\n",
    "\n",
    "        # Formatear tabla de detecciones\n",
    "        tabla_detecciones = [\n",
    "            [d['numero'], f\"{d['confianza']:.3f}\"]\n",
    "            for d in detecciones\n",
    "        ]\n",
    "\n",
    "        return imagen_anotada, texto_stats, tabla_detecciones\n",
    "\n",
    "    def limpiar_todo():\n",
    "        \"\"\"Limpia todos los campos\"\"\"\n",
    "        return None, \"\", None\n",
    "\n",
    "    def exportar_resultados_csv(detecciones_tabla):\n",
    "        \"\"\"Exporta tabla actual a CSV\"\"\"\n",
    "        if not detecciones_tabla:\n",
    "            return \"No hay detecciones para exportar\"\n",
    "\n",
    "        detecciones = [\n",
    "            {\n",
    "                'numero': row[0],\n",
    "                'confianza': float(row[1]),\n",
    "                'bbox': {}\n",
    "            }\n",
    "            for row in detecciones_tabla\n",
    "        ]\n",
    "\n",
    "        filepath = analyzer.exportar_csv(detecciones)\n",
    "        return f\"Exportado a: {filepath}\"\n",
    "\n",
    "    # Crear interfaz con Blocks\n",
    "    with gr.Blocks(\n",
    "        title=\"Basketball Jersey Numbers OCR\",\n",
    "        theme=gr.themes.Soft()\n",
    "    ) as demo:\n",
    "\n",
    "        gr.Markdown(\"# Basketball Jersey Numbers OCR\")\n",
    "        gr.Markdown(\"Deteccion de numeros en camisetas de baloncesto - Inferencia Local GPU\")\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1):\n",
    "                imagen_entrada = gr.Image(\n",
    "                    label=\"Imagen de entrada\",\n",
    "                    type=\"numpy\",\n",
    "                    sources=[\"upload\", \"webcam\"]\n",
    "                )\n",
    "\n",
    "                confianza_slider = gr.Slider(\n",
    "                    minimum=0.1,\n",
    "                    maximum=0.9,\n",
    "                    value=0.4,\n",
    "                    step=0.05,\n",
    "                    label=\"Confianza minima\"\n",
    "                )\n",
    "\n",
    "                with gr.Row():\n",
    "                    btn_analizar = gr.Button(\"Analizar\", variant=\"primary\")\n",
    "                    btn_limpiar = gr.Button(\"Limpiar\")\n",
    "\n",
    "            with gr.Column(scale=1):\n",
    "                imagen_salida = gr.Image(\n",
    "                    label=\"Detecciones\",\n",
    "                    type=\"numpy\"\n",
    "                )\n",
    "\n",
    "                texto_stats = gr.Textbox(\n",
    "                    label=\"Estadisticas\",\n",
    "                    lines=6,\n",
    "                    interactive=False\n",
    "                )\n",
    "\n",
    "        gr.Markdown(\"### Historial de Detecciones\")\n",
    "\n",
    "        tabla_detecciones = gr.Dataframe(\n",
    "            headers=[\"Numero\", \"Confianza\"],\n",
    "            label=\"Resultados\",\n",
    "            interactive=False\n",
    "        )\n",
    "\n",
    "        with gr.Row():\n",
    "            btn_exportar = gr.Button(\"Exportar a CSV\")\n",
    "            texto_exportar = gr.Textbox(\n",
    "                label=\"Estado de exportacion\",\n",
    "                interactive=False\n",
    "            )\n",
    "\n",
    "        # Conectar eventos\n",
    "        btn_analizar.click(\n",
    "            fn=analizar_imagen,\n",
    "            inputs=[imagen_entrada, confianza_slider],\n",
    "            outputs=[imagen_salida, texto_stats, tabla_detecciones]\n",
    "        )\n",
    "\n",
    "        btn_limpiar.click(\n",
    "            fn=limpiar_todo,\n",
    "            outputs=[imagen_entrada, texto_stats, tabla_detecciones]\n",
    "        )\n",
    "\n",
    "        btn_exportar.click(\n",
    "            fn=exportar_resultados_csv,\n",
    "            inputs=[tabla_detecciones],\n",
    "            outputs=[texto_exportar]\n",
    "        )\n",
    "\n",
    "    return demo\n",
    "\n",
    "\n",
    "print(\"[OK] Funcion de interfaz Gradio definida\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Funcion de interfaz Gradio definida\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "main_execution",
    "ExecuteTime": {
     "end_time": "2026-02-03T22:33:58.862155300Z",
     "start_time": "2026-02-03T22:33:21.061497200Z"
    }
   },
   "source": "# CELDA 6: Ejecucion Principal\n# IMPORTANTE: Ingresa tu API key de Roboflow antes de ejecutar\n\n# Configuracion\nROBOFLOW_API_KEY = \"\"  # INGRESA TU API KEY AQUI\n\nif not ROBOFLOW_API_KEY:\n    print(\"[ERROR] Debes ingresar tu Roboflow API key en la variable ROBOFLOW_API_KEY\")\n    print(\"\\nInstrucciones:\")\n    print(\"1. Ve a https://app.roboflow.com\")\n    print(\"2. Settings > API Keys\")\n    print(\"3. Copia tu Private API Key\")\n    print(\"4. Pegala en la variable ROBOFLOW_API_KEY arriba\")\nelse:\n    print(\"=\" * 70)\n    print(\"BASKETBALL JERSEY NUMBERS OCR - INFERENCIA LOCAL\")\n    print(\"=\" * 70)\n\n    # Cerrar cualquier demo de Gradio anterior\n    try:\n        import gradio as gr\n        gr.close_all()\n        print(\"\\n[INFO] Cerrando sesiones anteriores de Gradio...\")\n    except:\n        pass\n\n    # Inicializar analizador\n    print(\"\\nInicializando analizador...\")\n    analyzer = JerseyAnalyzer(api_key=ROBOFLOW_API_KEY)\n\n    # Crear y lanzar interfaz Gradio\n    print(\"\\nLanzando interfaz Gradio...\")\n    print(\"Se generara una URL publica que puedes abrir en cualquier navegador\")\n    \n    demo = crear_interfaz_gradio(analyzer)\n    \n    # Lanzar sin especificar puerto fijo (Gradio encuentra uno libre automaticamente)\n    demo.launch(\n        share=True,  # Genera URL publica\n        show_error=True,\n        debug=True\n    )",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usage_instructions"
   },
   "source": [
    "## Instrucciones de Uso\n",
    "\n",
    "### 1. Ejecutar Celdas en Orden\n",
    "1. Celda 1: Instalacion de dependencias (2-3 minutos)\n",
    "2. Celda 2: Verificacion de GPU\n",
    "3. Celda 3: Importaciones\n",
    "4. Celda 4: Clase JerseyAnalyzer\n",
    "5. Celda 5: Interfaz Gradio\n",
    "6. Celda 6: Ejecucion (ingresa tu API key primero)\n",
    "\n",
    "### 2. Obtener API Key de Roboflow\n",
    "1. Ir a https://app.roboflow.com\n",
    "2. Settings > API Keys\n",
    "3. Copiar Private API Key\n",
    "4. Pegar en variable `ROBOFLOW_API_KEY` de la Celda 6\n",
    "\n",
    "### 3. Usar la Interfaz\n",
    "- Subir imagen de camiseta de baloncesto\n",
    "- Ajustar slider de confianza minima (0.1 - 0.9)\n",
    "- Hacer clic en \"Analizar\"\n",
    "- Ver resultados con bounding boxes\n",
    "- Exportar a CSV si es necesario\n",
    "\n",
    "### 4. Archivos Generados\n",
    "- `/content/jersey_log.csv` - Historial completo de detecciones\n",
    "- `/content/outputs/detections/` - Exportaciones CSV individuales\n",
    "\n",
    "### 5. Notas Importantes\n",
    "- La API key solo se usa para descargar el modelo (primera vez)\n",
    "- Todas las inferencias son locales en GPU T4 (costo cero)\n",
    "- El modelo se cachea, la segunda ejecucion es instantanea\n",
    "- La sesion de Colab expira tras 12 horas de inactividad"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}