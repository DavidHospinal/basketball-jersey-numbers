================================================================================
CELDA 4 CORREGIDA - JerseyAnalyzer con soporte VLM
================================================================================

INSTRUCCIONES:
1. En el notebook de Colab, borrar el contenido de la Celda 4
2. Copiar y pegar TODO el codigo de abajo
3. Ejecutar la celda (Shift+Enter)
4. Volver a ejecutar Celda 6 para reiniciar el analizador

================================================================================
CODIGO CORREGIDO:
================================================================================

# CELDA 4: Clase JerseyAnalyzer (VERSION CORREGIDA)
# Analizador de dorsales con soporte para respuestas VLM y YOLO

import cv2

class JerseyAnalyzer:
    """Analizador de numeros de camisetas con soporte VLM y YOLO"""

    def __init__(self, api_key: str, model_id: str = "basketball-jersey-numbers-ocr/7"):
        """
        Inicializa el analizador con inferencia local en GPU

        Args:
            api_key: Roboflow API key (solo para descargar modelo)
            model_id: ID del modelo en formato workspace/project/version
        """
        self.api_key = api_key
        self.model_id = model_id
        self.model = None

        # Usar rutas de Colab (/content/)
        self.output_dir = Path("/content/outputs/detections")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.csv_log = Path("/content/jersey_log.csv")

        # Inicializar CSV si no existe
        if not self.csv_log.exists():
            with open(self.csv_log, 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                writer.writerow(['Timestamp', 'Numero Detectado', 'Confianza', 'Archivo'])

        self._cargar_modelo()

    def _cargar_modelo(self):
        """Carga el modelo para inferencia local en GPU"""
        try:
            print(f"\nCargando modelo {self.model_id} para inferencia local...")
            from inference import get_model

            # Inicializar modelo con API key (solo descarga, no consume creditos)
            self.model = get_model(
                model_id=self.model_id,
                api_key=self.api_key
            )
            print(f"[OK] Modelo cargado en GPU local")

        except Exception as e:
            print(f"[ERROR] Error al cargar modelo: {e}")
            raise

    def detectar_numeros(
        self,
        imagen: np.ndarray,
        confianza_min: float = 0.4
    ) -> Tuple[np.ndarray, List[Dict]]:
        """
        Detecta numeros en camiseta con inferencia local
        CORREGIDO: Maneja respuestas VLM y YOLO

        Args:
            imagen: Imagen en formato numpy array (RGB)
            confianza_min: Umbral minimo de confianza (0.0-1.0)

        Returns:
            Tupla de (imagen_anotada, lista_detecciones)
        """
        if self.model is None:
            raise RuntimeError("Modelo no inicializado")

        # Inferencia local (NO consume creditos de API)
        resultado = self.model.infer(imagen, confidence=confianza_min)

        # Manejar si resultado es lista
        if isinstance(resultado, list):
            resultado = resultado[0]

        # Detectar tipo de respuesta
        tipo_respuesta = type(resultado).__name__
        print(f"[DEBUG] Tipo de respuesta: {tipo_respuesta}")

        detecciones = []

        # CASO 1: Respuesta VLM (LMMInferenceResponse)
        if hasattr(resultado, 'response'):
            print("[INFO] Detectado modelo VLM")
            texto_respuesta = str(getattr(resultado, 'response', ''))
            print(f"[INFO] Respuesta del modelo: {texto_respuesta}")

            # Extraer numero del texto usando regex
            import re
            numeros = re.findall(r'\b\d+\b', texto_respuesta)

            if numeros:
                numero_detectado = numeros[0]
                print(f"[OK] Numero extraido: {numero_detectado}")

                # Crear deteccion con bbox centrado
                h, w = imagen.shape[:2]
                detecciones.append({
                    'numero': numero_detectado,
                    'confianza': 0.95,  # VLM tiene alta confianza
                    'bbox': {
                        'x': w // 2,
                        'y': h // 2,
                        'width': int(w * 0.6),
                        'height': int(h * 0.6)
                    }
                })
            else:
                print("[ADVERTENCIA] No se pudo extraer numero del texto")

        # CASO 2: Respuesta YOLO estandar
        elif hasattr(resultado, 'predictions'):
            print("[INFO] Detectado modelo YOLO")
            for pred in resultado.predictions:
                detecciones.append({
                    'numero': pred.class_name,
                    'confianza': round(pred.confidence, 3),
                    'bbox': {
                        'x': int(pred.x),
                        'y': int(pred.y),
                        'width': int(pred.width),
                        'height': int(pred.height)
                    }
                })

        # CASO 3: Tipo desconocido - debug
        else:
            print(f"[ERROR] Tipo de respuesta desconocido: {tipo_respuesta}")
            print(f"[DEBUG] Atributos: {dir(resultado)}")

        # Visualizar detecciones
        if detecciones:
            imagen_anotada = self._visualizar_detecciones_opencv(imagen, detecciones)
        else:
            imagen_anotada = imagen.copy()

        # Guardar en log
        self._guardar_en_log(detecciones)

        return imagen_anotada, detecciones

    def _visualizar_detecciones_opencv(self, imagen: np.ndarray, detecciones: List[Dict]) -> np.ndarray:
        """
        Dibuja bounding boxes con OpenCV (funciona para VLM y YOLO)
        """
        img = imagen.copy()

        for det in detecciones:
            bbox = det['bbox']
            numero = det['numero']
            conf = det['confianza']

            # Calcular coordenadas del rectangulo
            x1 = int(bbox['x'] - bbox['width'] / 2)
            y1 = int(bbox['y'] - bbox['height'] / 2)
            x2 = int(bbox['x'] + bbox['width'] / 2)
            y2 = int(bbox['y'] + bbox['height'] / 2)

            # Asegurar que coordenadas esten dentro de la imagen
            h, w = img.shape[:2]
            x1, x2 = max(0, x1), min(w, x2)
            y1, y2 = max(0, y1), min(h, y2)

            # Dibujar bounding box verde
            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 3)

            # Preparar etiqueta
            label = f"{numero} ({conf:.2f})"

            # Calcular tamaño del texto
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 1.2
            thickness = 2
            (text_w, text_h), _ = cv2.getTextSize(label, font, font_scale, thickness)

            # Dibujar fondo para el texto
            cv2.rectangle(img, (x1, y1 - text_h - 10), (x1 + text_w, y1), (0, 255, 0), -1)

            # Dibujar texto
            cv2.putText(img, label, (x1, y1 - 5),
                       font, font_scale, (0, 0, 0), thickness)

        return img

    def _guardar_en_log(self, detecciones: List[Dict]):
        """Añade detecciones al archivo CSV de log"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        with open(self.csv_log, 'a', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            for det in detecciones:
                writer.writerow([
                    timestamp,
                    det['numero'],
                    det['confianza'],
                    'gradio_upload'
                ])

    def calcular_estadisticas(self, detecciones: List[Dict]) -> Dict:
        """Calcula estadisticas de las detecciones"""
        if not detecciones:
            return {
                'total': 0,
                'confianza_promedio': 0.0,
                'confianza_max': 0.0,
                'confianza_min': 0.0
            }

        confianzas = [d['confianza'] for d in detecciones]

        return {
            'total': len(detecciones),
            'confianza_promedio': round(np.mean(confianzas), 3),
            'confianza_max': round(max(confianzas), 3),
            'confianza_min': round(min(confianzas), 3)
        }

    def exportar_csv(self, detecciones: List[Dict], filename: str = None) -> str:
        """Exporta detecciones actuales a CSV"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"detecciones_{timestamp}.csv"

        filepath = self.output_dir / filename

        with open(filepath, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=['numero', 'confianza', 'bbox'])
            writer.writeheader()
            writer.writerows(detecciones)

        return str(filepath)


print("[OK] Clase JerseyAnalyzer definida (VERSION CORREGIDA con soporte VLM)")

================================================================================
FIN DEL CODIGO
================================================================================

NOTAS:
- Esta version detecta automaticamente si el modelo es VLM o YOLO
- Usa OpenCV para dibujar en lugar de supervision (mas compatible)
- Extrae numeros del texto si el modelo retorna respuesta VLM
- Muestra mensajes de debug para diagnosticar el tipo de respuesta

================================================================================
