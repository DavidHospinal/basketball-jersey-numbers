{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Basketball Jersey Numbers OCR - Google Colab\n",
    "\n",
    "Sistema de deteccion de numeros en camisetas de baloncesto usando YOLOv8\n",
    "\n",
    "**Modelo**: basketball-jersey-numbers-ocr/7  \n",
    "**GPU**: NVIDIA Tesla T4  \n",
    "**Inferencia**: 100% local (costo cero)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_instructions"
   },
   "source": [
    "## Configuracion del Runtime\n",
    "\n",
    "**IMPORTANTE**: Antes de ejecutar, verifica que el runtime tenga GPU:\n",
    "\n",
    "1. Runtime > Change runtime type\n",
    "2. Hardware accelerator: **GPU (T4)**\n",
    "3. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "# CELDA 1: Instalacion de dependencias\n",
    "# Ejecutar esta celda primero (tarda ~2-3 minutos)\n",
    "\n",
    "print(\"Instalando dependencias para Basketball Jersey OCR...\")\n",
    "print(\"Este proceso puede tardar 2-3 minutos\\n\")\n",
    "\n",
    "# Instalar dependencias principales\n",
    "!pip install -q inference supervision gradio roboflow pillow\n",
    "\n",
    "print(\"\\n[OK] Dependencias instaladas correctamente\")\n",
    "print(\"Nota: Los warnings de compatibilidad de pandas/cryptography son normales y no afectan el funcionamiento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "verify_gpu"
   },
   "outputs": [],
   "source": [
    "# CELDA 2: Verificacion de GPU\n",
    "# Confirma que estas usando GPU Tesla T4\n",
    "\n",
    "import torch\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"VERIFICACION DE GPU\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU disponible: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Memoria total: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"Memoria asignada: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
    "    print(f\"Memoria en cache: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n",
    "    print(\"\\n[OK] GPU detectada correctamente\")\n",
    "else:\n",
    "    print(\"[ERROR] GPU no detectada\")\n",
    "    print(\"Verifica: Runtime > Change runtime type > GPU\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# CELDA 3: Importaciones\n",
    "\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "\n",
    "print(\"[OK] Modulos importados correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jersey_analyzer_class"
   },
   "outputs": [],
   "source": [
    "# CELDA 4: Clase JerseyAnalyzer\n",
    "# Analizador de dorsales con inferencia local en GPU\n",
    "\n",
    "class JerseyAnalyzer:\n",
    "    \"\"\"Analizador de numeros de camisetas de baloncesto con inferencia local\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str, model_id: str = \"basketball-jersey-numbers-ocr/7\"):\n",
    "        \"\"\"\n",
    "        Inicializa el analizador con inferencia local en GPU\n",
    "\n",
    "        Args:\n",
    "            api_key: Roboflow API key (solo para descargar modelo)\n",
    "            model_id: ID del modelo en formato workspace/project/version\n",
    "        \"\"\"\n",
    "        self.api_key = api_key\n",
    "        self.model_id = model_id\n",
    "        self.model = None\n",
    "        \n",
    "        # Usar rutas de Colab (/content/)\n",
    "        self.output_dir = Path(\"/content/outputs/detections\")\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.csv_log = Path(\"/content/jersey_log.csv\")\n",
    "\n",
    "        # Inicializar CSV si no existe\n",
    "        if not self.csv_log.exists():\n",
    "            with open(self.csv_log, 'w', newline='', encoding='utf-8') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(['Timestamp', 'Numero Detectado', 'Confianza', 'Archivo'])\n",
    "\n",
    "        self._cargar_modelo()\n",
    "\n",
    "    def _cargar_modelo(self):\n",
    "        \"\"\"Carga el modelo para inferencia local en GPU\"\"\"\n",
    "        try:\n",
    "            print(f\"\\nCargando modelo {self.model_id} para inferencia local...\")\n",
    "            from inference import get_model\n",
    "\n",
    "            # Inicializar modelo con API key (solo descarga, no consume creditos)\n",
    "            self.model = get_model(\n",
    "                model_id=self.model_id,\n",
    "                api_key=self.api_key\n",
    "            )\n",
    "            print(f\"[OK] Modelo cargado en GPU local\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Error al cargar modelo: {e}\")\n",
    "            raise\n",
    "\n",
    "    def detectar_numeros(\n",
    "        self,\n",
    "        imagen: np.ndarray,\n",
    "        confianza_min: float = 0.4\n",
    "    ) -> Tuple[np.ndarray, List[Dict]]:\n",
    "        \"\"\"\n",
    "        Detecta numeros en camiseta con inferencia local\n",
    "\n",
    "        Args:\n",
    "            imagen: Imagen en formato numpy array (RGB)\n",
    "            confianza_min: Umbral minimo de confianza (0.0-1.0)\n",
    "\n",
    "        Returns:\n",
    "            Tupla de (imagen_anotada, lista_detecciones)\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Modelo no inicializado\")\n",
    "\n",
    "        # Inferencia local (NO consume creditos de API)\n",
    "        resultados = self.model.infer(imagen, confidence=confianza_min)[0]\n",
    "\n",
    "        # Procesar detecciones\n",
    "        detecciones = []\n",
    "        for pred in resultados.predictions:\n",
    "            detecciones.append({\n",
    "                'numero': pred.class_name,\n",
    "                'confianza': round(pred.confidence, 3),\n",
    "                'bbox': {\n",
    "                    'x': int(pred.x),\n",
    "                    'y': int(pred.y),\n",
    "                    'width': int(pred.width),\n",
    "                    'height': int(pred.height)\n",
    "                }\n",
    "            })\n",
    "\n",
    "        # Visualizar con supervision\n",
    "        imagen_anotada = self._visualizar_detecciones(imagen, resultados)\n",
    "\n",
    "        # Guardar en log CSV\n",
    "        self._guardar_en_log(detecciones)\n",
    "\n",
    "        return imagen_anotada, detecciones\n",
    "\n",
    "    def _visualizar_detecciones(self, imagen: np.ndarray, resultados) -> np.ndarray:\n",
    "        \"\"\"Dibuja bounding boxes y etiquetas con supervision\"\"\"\n",
    "        try:\n",
    "            import supervision as sv\n",
    "\n",
    "            # Convertir resultados a formato supervision\n",
    "            detections = sv.Detections.from_inference(resultados)\n",
    "\n",
    "            # Configurar anotadores\n",
    "            box_annotator = sv.BoxAnnotator(\n",
    "                thickness=3,\n",
    "                color=sv.Color.from_hex(\"#00FF00\")\n",
    "            )\n",
    "\n",
    "            label_annotator = sv.LabelAnnotator(\n",
    "                text_scale=1.2,\n",
    "                text_thickness=2,\n",
    "                text_color=sv.Color.WHITE,\n",
    "                color=sv.Color.from_hex(\"#00FF00\")\n",
    "            )\n",
    "\n",
    "            # Generar etiquetas con clase y confianza\n",
    "            labels = [\n",
    "                f\"{pred.class_name} ({pred.confidence:.2f})\"\n",
    "                for pred in resultados.predictions\n",
    "            ]\n",
    "\n",
    "            # Anotar imagen\n",
    "            imagen_anotada = box_annotator.annotate(\n",
    "                scene=imagen.copy(),\n",
    "                detections=detections\n",
    "            )\n",
    "            imagen_anotada = label_annotator.annotate(\n",
    "                scene=imagen_anotada,\n",
    "                detections=detections,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            return imagen_anotada\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ADVERTENCIA] Error en visualizacion: {e}\")\n",
    "            return imagen\n",
    "\n",
    "    def _guardar_en_log(self, detecciones: List[Dict]):\n",
    "        \"\"\"AÃ±ade detecciones al archivo CSV de log\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        with open(self.csv_log, 'a', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for det in detecciones:\n",
    "                writer.writerow([\n",
    "                    timestamp,\n",
    "                    det['numero'],\n",
    "                    det['confianza'],\n",
    "                    'gradio_upload'\n",
    "                ])\n",
    "\n",
    "    def calcular_estadisticas(self, detecciones: List[Dict]) -> Dict:\n",
    "        \"\"\"Calcula estadisticas de las detecciones\"\"\"\n",
    "        if not detecciones:\n",
    "            return {\n",
    "                'total': 0,\n",
    "                'confianza_promedio': 0.0,\n",
    "                'confianza_max': 0.0,\n",
    "                'confianza_min': 0.0\n",
    "            }\n",
    "\n",
    "        confianzas = [d['confianza'] for d in detecciones]\n",
    "\n",
    "        return {\n",
    "            'total': len(detecciones),\n",
    "            'confianza_promedio': round(np.mean(confianzas), 3),\n",
    "            'confianza_max': round(max(confianzas), 3),\n",
    "            'confianza_min': round(min(confianzas), 3)\n",
    "        }\n",
    "\n",
    "    def exportar_csv(self, detecciones: List[Dict], filename: str = None) -> str:\n",
    "        \"\"\"Exporta detecciones actuales a CSV\"\"\"\n",
    "        if filename is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"detecciones_{timestamp}.csv\"\n",
    "\n",
    "        filepath = self.output_dir / filename\n",
    "\n",
    "        with open(filepath, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=['numero', 'confianza', 'bbox'])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(detecciones)\n",
    "\n",
    "        return str(filepath)\n",
    "\n",
    "\n",
    "print(\"[OK] Clase JerseyAnalyzer definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gradio_interface"
   },
   "outputs": [],
   "source": [
    "# CELDA 5: Interfaz Gradio\n",
    "# Define la interfaz web para deteccion de dorsales\n",
    "\n",
    "def crear_interfaz_gradio(analyzer: JerseyAnalyzer):\n",
    "    \"\"\"Crea interfaz Gradio profesional con todas las funcionalidades\"\"\"\n",
    "\n",
    "    def analizar_imagen(imagen, confianza_min):\n",
    "        \"\"\"Procesa imagen y retorna resultados\"\"\"\n",
    "        if imagen is None:\n",
    "            return None, \"No se cargo ninguna imagen\", None\n",
    "\n",
    "        # Convertir a numpy array RGB\n",
    "        if isinstance(imagen, Image.Image):\n",
    "            imagen = np.array(imagen)\n",
    "\n",
    "        # Detectar numeros\n",
    "        imagen_anotada, detecciones = analyzer.detectar_numeros(\n",
    "            imagen,\n",
    "            confianza_min=confianza_min\n",
    "        )\n",
    "\n",
    "        # Calcular estadisticas\n",
    "        stats = analyzer.calcular_estadisticas(detecciones)\n",
    "\n",
    "        # Formatear resultados\n",
    "        texto_stats = f\"\"\"\n",
    "ESTADISTICAS DE DETECCION:\n",
    "- Total de numeros detectados: {stats['total']}\n",
    "- Confianza promedio: {stats['confianza_promedio']:.3f}\n",
    "- Confianza maxima: {stats['confianza_max']:.3f}\n",
    "- Confianza minima: {stats['confianza_min']:.3f}\n",
    "        \"\"\"\n",
    "\n",
    "        # Formatear tabla de detecciones\n",
    "        tabla_detecciones = [\n",
    "            [d['numero'], f\"{d['confianza']:.3f}\"]\n",
    "            for d in detecciones\n",
    "        ]\n",
    "\n",
    "        return imagen_anotada, texto_stats, tabla_detecciones\n",
    "\n",
    "    def limpiar_todo():\n",
    "        \"\"\"Limpia todos los campos\"\"\"\n",
    "        return None, \"\", None\n",
    "\n",
    "    def exportar_resultados_csv(detecciones_tabla):\n",
    "        \"\"\"Exporta tabla actual a CSV\"\"\"\n",
    "        if not detecciones_tabla:\n",
    "            return \"No hay detecciones para exportar\"\n",
    "\n",
    "        detecciones = [\n",
    "            {\n",
    "                'numero': row[0],\n",
    "                'confianza': float(row[1]),\n",
    "                'bbox': {}\n",
    "            }\n",
    "            for row in detecciones_tabla\n",
    "        ]\n",
    "\n",
    "        filepath = analyzer.exportar_csv(detecciones)\n",
    "        return f\"Exportado a: {filepath}\"\n",
    "\n",
    "    # Crear interfaz con Blocks\n",
    "    with gr.Blocks(\n",
    "        title=\"Basketball Jersey Numbers OCR\",\n",
    "        theme=gr.themes.Soft()\n",
    "    ) as demo:\n",
    "\n",
    "        gr.Markdown(\"# Basketball Jersey Numbers OCR\")\n",
    "        gr.Markdown(\"Deteccion de numeros en camisetas de baloncesto - Inferencia Local GPU\")\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1):\n",
    "                imagen_entrada = gr.Image(\n",
    "                    label=\"Imagen de entrada\",\n",
    "                    type=\"numpy\",\n",
    "                    sources=[\"upload\", \"webcam\"]\n",
    "                )\n",
    "\n",
    "                confianza_slider = gr.Slider(\n",
    "                    minimum=0.1,\n",
    "                    maximum=0.9,\n",
    "                    value=0.4,\n",
    "                    step=0.05,\n",
    "                    label=\"Confianza minima\"\n",
    "                )\n",
    "\n",
    "                with gr.Row():\n",
    "                    btn_analizar = gr.Button(\"Analizar\", variant=\"primary\")\n",
    "                    btn_limpiar = gr.Button(\"Limpiar\")\n",
    "\n",
    "            with gr.Column(scale=1):\n",
    "                imagen_salida = gr.Image(\n",
    "                    label=\"Detecciones\",\n",
    "                    type=\"numpy\"\n",
    "                )\n",
    "\n",
    "                texto_stats = gr.Textbox(\n",
    "                    label=\"Estadisticas\",\n",
    "                    lines=6,\n",
    "                    interactive=False\n",
    "                )\n",
    "\n",
    "        gr.Markdown(\"### Historial de Detecciones\")\n",
    "\n",
    "        tabla_detecciones = gr.Dataframe(\n",
    "            headers=[\"Numero\", \"Confianza\"],\n",
    "            label=\"Resultados\",\n",
    "            interactive=False\n",
    "        )\n",
    "\n",
    "        with gr.Row():\n",
    "            btn_exportar = gr.Button(\"Exportar a CSV\")\n",
    "            texto_exportar = gr.Textbox(\n",
    "                label=\"Estado de exportacion\",\n",
    "                interactive=False\n",
    "            )\n",
    "\n",
    "        # Conectar eventos\n",
    "        btn_analizar.click(\n",
    "            fn=analizar_imagen,\n",
    "            inputs=[imagen_entrada, confianza_slider],\n",
    "            outputs=[imagen_salida, texto_stats, tabla_detecciones]\n",
    "        )\n",
    "\n",
    "        btn_limpiar.click(\n",
    "            fn=limpiar_todo,\n",
    "            outputs=[imagen_entrada, texto_stats, tabla_detecciones]\n",
    "        )\n",
    "\n",
    "        btn_exportar.click(\n",
    "            fn=exportar_resultados_csv,\n",
    "            inputs=[tabla_detecciones],\n",
    "            outputs=[texto_exportar]\n",
    "        )\n",
    "\n",
    "    return demo\n",
    "\n",
    "\n",
    "print(\"[OK] Funcion de interfaz Gradio definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "main_execution"
   },
   "outputs": [],
   "source": [
    "# CELDA 6: Ejecucion Principal\n",
    "# IMPORTANTE: Ingresa tu API key de Roboflow antes de ejecutar\n",
    "\n",
    "# Configuracion\n",
    "ROBOFLOW_API_KEY = \"\"  # INGRESA TU API KEY AQUI\n",
    "\n",
    "if not ROBOFLOW_API_KEY:\n",
    "    print(\"[ERROR] Debes ingresar tu Roboflow API key en la variable ROBOFLOW_API_KEY\")\n",
    "    print(\"\\nInstrucciones:\")\n",
    "    print(\"1. Ve a https://app.roboflow.com\")\n",
    "    print(\"2. Settings > API Keys\")\n",
    "    print(\"3. Copia tu Private API Key\")\n",
    "    print(\"4. Pegala en la variable ROBOFLOW_API_KEY arriba\")\n",
    "else:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"BASKETBALL JERSEY NUMBERS OCR - INFERENCIA LOCAL\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Inicializar analizador\n",
    "    print(\"\\nInicializando analizador...\")\n",
    "    analyzer = JerseyAnalyzer(api_key=ROBOFLOW_API_KEY)\n",
    "\n",
    "    # Crear y lanzar interfaz Gradio\n",
    "    print(\"\\nLanzando interfaz Gradio...\")\n",
    "    print(\"Se generara una URL publica que puedes abrir en cualquier navegador\")\n",
    "    \n",
    "    demo = crear_interfaz_gradio(analyzer)\n",
    "    \n",
    "    demo.launch(\n",
    "        share=True,  # Genera URL publica\n",
    "        server_name=\"0.0.0.0\",\n",
    "        server_port=7860,\n",
    "        show_error=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usage_instructions"
   },
   "source": [
    "## Instrucciones de Uso\n",
    "\n",
    "### 1. Ejecutar Celdas en Orden\n",
    "1. Celda 1: Instalacion de dependencias (2-3 minutos)\n",
    "2. Celda 2: Verificacion de GPU\n",
    "3. Celda 3: Importaciones\n",
    "4. Celda 4: Clase JerseyAnalyzer\n",
    "5. Celda 5: Interfaz Gradio\n",
    "6. Celda 6: Ejecucion (ingresa tu API key primero)\n",
    "\n",
    "### 2. Obtener API Key de Roboflow\n",
    "1. Ir a https://app.roboflow.com\n",
    "2. Settings > API Keys\n",
    "3. Copiar Private API Key\n",
    "4. Pegar en variable `ROBOFLOW_API_KEY` de la Celda 6\n",
    "\n",
    "### 3. Usar la Interfaz\n",
    "- Subir imagen de camiseta de baloncesto\n",
    "- Ajustar slider de confianza minima (0.1 - 0.9)\n",
    "- Hacer clic en \"Analizar\"\n",
    "- Ver resultados con bounding boxes\n",
    "- Exportar a CSV si es necesario\n",
    "\n",
    "### 4. Archivos Generados\n",
    "- `/content/jersey_log.csv` - Historial completo de detecciones\n",
    "- `/content/outputs/detections/` - Exportaciones CSV individuales\n",
    "\n",
    "### 5. Notas Importantes\n",
    "- La API key solo se usa para descargar el modelo (primera vez)\n",
    "- Todas las inferencias son locales en GPU T4 (costo cero)\n",
    "- El modelo se cachea, la segunda ejecucion es instantanea\n",
    "- La sesion de Colab expira tras 12 horas de inactividad"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
